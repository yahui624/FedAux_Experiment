Arguments:
	       batch_size : 10
	clients_per_round : 10
	          dataset : synthetic_1_1
	     drop_percent : 0.0
	       eval_every : 1
	    learning_rate : 0.01
	            model : mclr
	     model_params : (10,)
	               mu : 0.0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedprox
	             seed : 0
Using Federated prox to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/5.44k flops)
  dense/kernel/Regularizer/l2_regularizer (1/1.80k flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (1.80k/1.80k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  PGD/update_dense/kernel/AssignSub (600/600 flops)
  PGD/update_dense/kernel/mul (600/600 flops)
  PGD/update_dense/kernel/mul_1 (600/600 flops)
  PGD/update_dense/kernel/sub (600/600 flops)
  PGD/update_dense/bias/AssignSub (10/10 flops)
  PGD/update_dense/bias/mul (10/10 flops)
  PGD/update_dense/bias/mul_1 (10/10 flops)
  PGD/update_dense/bias/sub (10/10 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
30 Clients in Total
Training with 10 workers ---
At round 0 accuracy: 0.3016605166051661
At round 0 training accuracy: 0.28739583333333335
At round 0 training loss: 2.814805432880918
gradient difference: 116.13141207625425
At round 1 accuracy: 0.3671586715867159
At round 1 training accuracy: 0.346875
At round 1 training loss: 3.2193595414608716
gradient difference: 112.94895449587351
At round 2 accuracy: 0.37546125461254615
At round 2 training accuracy: 0.36
At round 2 training loss: 3.5592060027395687
gradient difference: 111.49006026291163
At round 3 accuracy: 0.09317343173431734
At round 3 training accuracy: 0.09291666666666666
At round 3 training loss: 2.977609865727524
gradient difference: 120.86324356691928
At round 4 accuracy: 0.5166051660516605
At round 4 training accuracy: 0.5432291666666667
At round 4 training loss: 1.7869777129435291
gradient difference: 93.28807774242141
At round 5 accuracy: 0.522140221402214
At round 5 training accuracy: 0.5492708333333334
At round 5 training loss: 2.1073130104566613
gradient difference: 102.08505331901317
At round 6 accuracy: 0.5239852398523985
At round 6 training accuracy: 0.5475
At round 6 training loss: 1.953506039933612
gradient difference: 100.18949323099613
At round 7 accuracy: 0.551660516605166
At round 7 training accuracy: 0.5420833333333334
At round 7 training loss: 1.6057340681056183
gradient difference: 97.02482814901288
At round 8 accuracy: 0.43634686346863466
At round 8 training accuracy: 0.44583333333333336
At round 8 training loss: 1.6408086433261633
gradient difference: 107.60830723807162
At round 9 accuracy: 0.5581180811808119
At round 9 training accuracy: 0.5953125
At round 9 training loss: 1.7116859018957864
gradient difference: 99.89840229636943
At round 10 accuracy: 0.5618081180811808
At round 10 training accuracy: 0.5920833333333333
At round 10 training loss: 1.481392042307804
gradient difference: 97.27194222945779
At round 11 accuracy: 0.5959409594095941
At round 11 training accuracy: 0.6295833333333334
At round 11 training loss: 1.3787924472087374
gradient difference: 92.90138154857262
At round 12 accuracy: 0.5212177121771218
At round 12 training accuracy: 0.5088541666666667
At round 12 training loss: 1.7680403205441932
gradient difference: 116.99433292640532
At round 13 accuracy: 0.5562730627306273
At round 13 training accuracy: 0.5969791666666666
At round 13 training loss: 1.756489584983016
gradient difference: 107.101352017335
At round 14 accuracy: 0.5710332103321033
At round 14 training accuracy: 0.6023958333333334
At round 14 training loss: 1.8580381115805358
gradient difference: 109.82633415683235
At round 15 accuracy: 0.5156826568265682
At round 15 training accuracy: 0.5416666666666666
At round 15 training loss: 2.044740356259669
gradient difference: 118.28492500259686
At round 16 accuracy: 0.4252767527675277
At round 16 training accuracy: 0.44375
At round 16 training loss: 2.5838474442840864
gradient difference: 137.14204214510997
At round 17 accuracy: 0.4151291512915129
At round 17 training accuracy: 0.43802083333333336
At round 17 training loss: 2.5515944728224227
gradient difference: 136.41526427889536
At round 18 accuracy: 0.4225092250922509
At round 18 training accuracy: 0.4476041666666667
At round 18 training loss: 2.1988376177474858
gradient difference: 129.0815605418117
At round 19 accuracy: 0.4086715867158672
At round 19 training accuracy: 0.43135416666666665
At round 19 training loss: 2.4894586934971934
gradient difference: 133.1199762657048
At round 20 accuracy: 0.41051660516605165
At round 20 training accuracy: 0.43833333333333335
At round 20 training loss: 2.2302272962095837
gradient difference: 131.31026793200834
At round 21 accuracy: 0.4132841328413284
At round 21 training accuracy: 0.43916666666666665
At round 21 training loss: 2.2128028331246847
gradient difference: 130.7992130105212
At round 22 accuracy: 0.42066420664206644
At round 22 training accuracy: 0.44854166666666667
At round 22 training loss: 2.437929041963071
gradient difference: 130.91678955447293
At round 23 accuracy: 0.5415129151291513
At round 23 training accuracy: 0.5692708333333333
At round 23 training loss: 1.5609378301228085
gradient difference: 109.9391202301917
At round 24 accuracy: 0.5691881918819188
At round 24 training accuracy: 0.6030208333333333
At round 24 training loss: 1.6144662154869487
gradient difference: 110.61715265197476
At round 25 accuracy: 0.5839483394833949
At round 25 training accuracy: 0.5982291666666667
At round 25 training loss: 1.5220084147434683
gradient difference: 110.89629329416208
At round 26 accuracy: 0.5885608856088561
At round 26 training accuracy: 0.625
At round 26 training loss: 1.4209794529993087
gradient difference: 104.68177229296361
At round 27 accuracy: 0.5839483394833949
At round 27 training accuracy: 0.585625
At round 27 training loss: 1.4662803249713035
gradient difference: 111.32873680641374
At round 28 accuracy: 0.5756457564575646
At round 28 training accuracy: 0.5772916666666666
At round 28 training loss: 1.5824807145198185
gradient difference: 114.57593470895675
At round 29 accuracy: 0.5479704797047971
At round 29 training accuracy: 0.5404166666666667
At round 29 training loss: 1.6361925876699388
gradient difference: 119.67440622730798
At round 30 accuracy: 0.5811808118081181
At round 30 training accuracy: 0.5840625
At round 30 training loss: 1.487213106402196
gradient difference: 110.97146306223542
At round 31 accuracy: 0.5876383763837638
At round 31 training accuracy: 0.6239583333333333
At round 31 training loss: 1.4988427543671181
gradient difference: 106.89605458119809
At round 32 accuracy: 0.5876383763837638
At round 32 training accuracy: 0.6191666666666666
At round 32 training loss: 1.5583161821744094
gradient difference: 109.81551566489607
At round 33 accuracy: 0.5765682656826568
At round 33 training accuracy: 0.6105208333333333
At round 33 training loss: 1.6260296867787838
gradient difference: 111.1938268103453
At round 34 accuracy: 0.577490774907749
At round 34 training accuracy: 0.6133333333333333
At round 34 training loss: 1.6393290445456903
gradient difference: 111.20098134632117
At round 35 accuracy: 0.5830258302583026
At round 35 training accuracy: 0.6140625
At round 35 training loss: 1.6703548966441304
gradient difference: 113.0056565481218
At round 36 accuracy: 0.5138376383763837
At round 36 training accuracy: 0.5086458333333334
At round 36 training loss: 1.8580727555789054
gradient difference: 129.58740393568775
At round 37 accuracy: 0.5784132841328413
At round 37 training accuracy: 0.6071875
At round 37 training loss: 1.633878820342943
gradient difference: 112.40411271740916
At round 38 accuracy: 0.4797047970479705
At round 38 training accuracy: 0.47270833333333334
At round 38 training loss: 2.131132379565388
gradient difference: 142.08808813306007
At round 39 accuracy: 0.4612546125461255
At round 39 training accuracy: 0.45625
At round 39 training loss: 2.3198516375540446
gradient difference: 147.96386796123983
At round 40 accuracy: 0.6070110701107011
At round 40 training accuracy: 0.6427083333333333
At round 40 training loss: 1.5370724407971526
gradient difference: 106.3519119030021
At round 41 accuracy: 0.6023985239852399
At round 41 training accuracy: 0.6416666666666667
At round 41 training loss: 1.57243548842147
gradient difference: 107.59906708279634
At round 42 accuracy: 0.6079335793357934
At round 42 training accuracy: 0.6370833333333333
At round 42 training loss: 1.5899668314649413
gradient difference: 108.80691508433247
At round 43 accuracy: 0.6014760147601476
At round 43 training accuracy: 0.6353125
At round 43 training loss: 1.6117247647419572
gradient difference: 108.71116385958287
At round 44 accuracy: 0.5987084870848709
At round 44 training accuracy: 0.619375
At round 44 training loss: 1.558214328189691
gradient difference: 110.51270977221127
At round 45 accuracy: 0.4584870848708487
At round 45 training accuracy: 0.4813541666666667
At round 45 training loss: 2.2048634355980905
gradient difference: 130.40330359875648
At round 46 accuracy: 0.4732472324723247
At round 46 training accuracy: 0.5016666666666667
At round 46 training loss: 1.974144540441533
gradient difference: 124.95248295827112
At round 47 accuracy: 0.4732472324723247
At round 47 training accuracy: 0.4977083333333333
At round 47 training loss: 1.9976636179443448
gradient difference: 126.54339999587589
At round 48 accuracy: 0.5922509225092251
At round 48 training accuracy: 0.6090625
At round 48 training loss: 1.5134618625448395
gradient difference: 107.34161409271854
At round 49 accuracy: 0.6042435424354243
At round 49 training accuracy: 0.641875
At round 49 training loss: 1.4766565539641305
gradient difference: 104.94656169078698
At round 50 accuracy: 0.6162361623616236
At round 50 training accuracy: 0.6436458333333334
At round 50 training loss: 1.5000078353394444
gradient difference: 105.60962763612613
At round 51 accuracy: 0.6171586715867159
At round 51 training accuracy: 0.6305208333333333
At round 51 training loss: 1.4908601858497907
gradient difference: 106.50774079097413
At round 52 accuracy: 0.6171586715867159
At round 52 training accuracy: 0.648125
At round 52 training loss: 1.4825270047613108
gradient difference: 103.19826187805212
At round 53 accuracy: 0.6236162361623616
At round 53 training accuracy: 0.6489583333333333
At round 53 training loss: 1.4945183102274313
gradient difference: 105.34963121246872
At round 54 accuracy: 0.6236162361623616
At round 54 training accuracy: 0.64875
At round 54 training loss: 1.5025407109952842
gradient difference: 105.62960579150091
At round 55 accuracy: 0.6190036900369004
At round 55 training accuracy: 0.6532291666666666
At round 55 training loss: 1.4635527807396527
gradient difference: 102.01196383377552
At round 56 accuracy: 0.6273062730627307
At round 56 training accuracy: 0.6522916666666667
At round 56 training loss: 1.4096524803868185
gradient difference: 100.74073598529306
At round 57 accuracy: 0.6263837638376384
At round 57 training accuracy: 0.6377083333333333
At round 57 training loss: 1.4040917812427507
gradient difference: 101.162930100344
At round 58 accuracy: 0.6236162361623616
At round 58 training accuracy: 0.6358333333333334
At round 58 training loss: 1.39004115938209
gradient difference: 100.02350188674129
At round 59 accuracy: 0.6070110701107011
At round 59 training accuracy: 0.5992708333333333
At round 59 training loss: 1.5149285545820992
gradient difference: 107.97667461702206
At round 60 accuracy: 0.6070110701107011
At round 60 training accuracy: 0.5958333333333333
At round 60 training loss: 1.478596733006028
gradient difference: 106.18808243537683
At round 61 accuracy: 0.5922509225092251
At round 61 training accuracy: 0.5780208333333333
At round 61 training loss: 1.485986749761117
gradient difference: 107.45120029400975
At round 62 accuracy: 0.6190036900369004
At round 62 training accuracy: 0.6233333333333333
At round 62 training loss: 1.3264770373748616
gradient difference: 94.71652365099686
At round 63 accuracy: 0.6153136531365314
At round 63 training accuracy: 0.6075
At round 63 training loss: 1.338768375357613
gradient difference: 97.17072919744032
At round 64 accuracy: 0.6383763837638377
At round 64 training accuracy: 0.6661458333333333
At round 64 training loss: 1.2596978457504884
gradient difference: 90.79336071913346
At round 65 accuracy: 0.6420664206642066
At round 65 training accuracy: 0.6569791666666667
At round 65 training loss: 1.3080732991655046
gradient difference: 94.00222677524397
At round 66 accuracy: 0.6254612546125461
At round 66 training accuracy: 0.6304166666666666
At round 66 training loss: 1.3096421331027523
gradient difference: 95.8554811904684
At round 67 accuracy: 0.6365313653136532
At round 67 training accuracy: 0.6580208333333334
At round 67 training loss: 1.2269831914190823
gradient difference: 90.94250603659957
At round 68 accuracy: 0.6254612546125461
At round 68 training accuracy: 0.6529166666666667
At round 68 training loss: 1.1831981358164922
gradient difference: 87.65331632288202
At round 69 accuracy: 0.6190036900369004
At round 69 training accuracy: 0.6546875
At round 69 training loss: 1.1592787780224656
gradient difference: 86.20470432115047
At round 70 accuracy: 0.6346863468634686
At round 70 training accuracy: 0.6573958333333333
At round 70 training loss: 1.206938329638603
gradient difference: 90.56218480444421
At round 71 accuracy: 0.6125461254612546
At round 71 training accuracy: 0.621875
At round 71 training loss: 1.3076419734597826
gradient difference: 97.99656582458167
At round 72 accuracy: 0.6300738007380073
At round 72 training accuracy: 0.6645833333333333
At round 72 training loss: 1.2399034852627664
gradient difference: 90.99901969832533
At round 73 accuracy: 0.6273062730627307
At round 73 training accuracy: 0.6419791666666667
At round 73 training loss: 1.2518745119155694
gradient difference: 94.67405336707685
At round 74 accuracy: 0.6171586715867159
At round 74 training accuracy: 0.616875
At round 74 training loss: 1.2909988947259263
gradient difference: 98.42566542314422
At round 75 accuracy: 0.5802583025830258
At round 75 training accuracy: 0.6
At round 75 training loss: 1.2634975068364291
gradient difference: 92.85907263773353
At round 76 accuracy: 0.5885608856088561
At round 76 training accuracy: 0.6153125
At round 76 training loss: 1.2574445152344802
gradient difference: 92.61966083897101
At round 77 accuracy: 0.5341328413284133
At round 77 training accuracy: 0.5528125
At round 77 training loss: 1.4472806873358786
gradient difference: 100.44518271445192
At round 78 accuracy: 0.6236162361623616
At round 78 training accuracy: 0.6545833333333333
At round 78 training loss: 1.186528032522959
gradient difference: 87.46206215245998
At round 79 accuracy: 0.6402214022140221
At round 79 training accuracy: 0.6639583333333333
At round 79 training loss: 1.1844676110583048
gradient difference: 87.06477913325043
At round 80 accuracy: 0.6420664206642066
At round 80 training accuracy: 0.6719791666666667
At round 80 training loss: 1.1527683775344242
gradient difference: 87.09066815592449
At round 81 accuracy: 0.49723247232472323
At round 81 training accuracy: 0.5230208333333334
At round 81 training loss: 1.671133310846053
gradient difference: 108.7597013065673
At round 82 accuracy: 0.5673431734317343
At round 82 training accuracy: 0.5858333333333333
At round 82 training loss: 1.3512998525115352
gradient difference: 96.76703592916883
At round 83 accuracy: 0.6236162361623616
At round 83 training accuracy: 0.6369791666666667
At round 83 training loss: 1.2315554357257983
gradient difference: 89.88907715072158
At round 84 accuracy: 0.6402214022140221
At round 84 training accuracy: 0.6735416666666667
At round 84 training loss: 1.1720267872093246
gradient difference: 86.92239757626088
At round 85 accuracy: 0.6402214022140221
At round 85 training accuracy: 0.673125
At round 85 training loss: 1.1867176999741544
gradient difference: 87.48217901911339
At round 86 accuracy: 0.6485239852398524
At round 86 training accuracy: 0.678125
At round 86 training loss: 1.1574649921059608
gradient difference: 81.81627111444875
At round 87 accuracy: 0.6466789667896679
At round 87 training accuracy: 0.6794791666666666
At round 87 training loss: 1.1303757544296482
gradient difference: 79.2843718634337
At round 88 accuracy: 0.559040590405904
At round 88 training accuracy: 0.5736458333333333
At round 88 training loss: 1.339102069127063
gradient difference: 93.64364646902271
At round 89 accuracy: 0.5636531365313653
At round 89 training accuracy: 0.5798958333333334
At round 89 training loss: 1.3073922913366307
gradient difference: 91.85705428986512
At round 90 accuracy: 0.5876383763837638
At round 90 training accuracy: 0.6070833333333333
At round 90 training loss: 1.2154277035159369
gradient difference: 88.5938861899556
At round 91 accuracy: 0.5083025830258303
At round 91 training accuracy: 0.5302083333333333
At round 91 training loss: 1.619321194610869
gradient difference: 102.3567901032877
At round 92 accuracy: 0.6420664206642066
At round 92 training accuracy: 0.6710416666666666
At round 92 training loss: 1.0747393330931663
gradient difference: 79.70582475237838
At round 93 accuracy: 0.6273062730627307
At round 93 training accuracy: 0.6310416666666666
At round 93 training loss: 1.1377651223509262
gradient difference: 88.87017219163039
At round 94 accuracy: 0.6540590405904059
At round 94 training accuracy: 0.66375
At round 94 training loss: 1.0376288379138956
gradient difference: 77.29271436762114
At round 95 accuracy: 0.6559040590405905
At round 95 training accuracy: 0.6611458333333333
At round 95 training loss: 1.0162652277698119
gradient difference: 74.50705888279413
At round 96 accuracy: 0.6263837638376384
At round 96 training accuracy: 0.6160416666666667
At round 96 training loss: 1.1276628806100537
gradient difference: 82.20452542658425
At round 97 accuracy: 0.6503690036900369
At round 97 training accuracy: 0.6497916666666667
At round 97 training loss: 1.0293604629828284
gradient difference: 76.60094523000231
At round 98 accuracy: 0.6614391143911439
At round 98 training accuracy: 0.6880208333333333
At round 98 training loss: 0.9909243041214844
gradient difference: 74.14098876375651
At round 99 accuracy: 0.6356088560885609
At round 99 training accuracy: 0.6382291666666666
At round 99 training loss: 1.1195241366699338
gradient difference: 84.4960971046125
At round 100 accuracy: 0.6559040590405905
At round 100 training accuracy: 0.671875
At round 100 training loss: 1.0748825934622437
gradient difference: 80.72433375313064
At round 101 accuracy: 0.6337638376383764
At round 101 training accuracy: 0.6355208333333333
At round 101 training loss: 1.1357539876457303
gradient difference: 86.82056588646591
At round 102 accuracy: 0.6236162361623616
At round 102 training accuracy: 0.6096875
At round 102 training loss: 1.1909775634886075
gradient difference: 89.88606752683775
At round 103 accuracy: 0.6559040590405905
At round 103 training accuracy: 0.6782291666666667
At round 103 training loss: 1.019798411540687
gradient difference: 79.27246200013582
At round 104 accuracy: 0.6291512915129152
At round 104 training accuracy: 0.629375
At round 104 training loss: 1.144477943930154
gradient difference: 88.03004076110996
At round 105 accuracy: 0.6559040590405905
At round 105 training accuracy: 0.6851041666666666
At round 105 training loss: 1.0636822571326048
gradient difference: 79.7864576412367
At round 106 accuracy: 0.6503690036900369
At round 106 training accuracy: 0.6792708333333334
At round 106 training loss: 1.0609488423292837
gradient difference: 81.84025618110782
At round 107 accuracy: 0.6457564575645757
At round 107 training accuracy: 0.675625
At round 107 training loss: 1.0872474536734322
gradient difference: 82.01088783399129
At round 108 accuracy: 0.5793357933579336
At round 108 training accuracy: 0.5966666666666667
At round 108 training loss: 1.267603092865708
gradient difference: 93.32661007383497
At round 109 accuracy: 0.6485239852398524
At round 109 training accuracy: 0.6829166666666666
At round 109 training loss: 1.0731129942337672
gradient difference: 82.62618055437063
At round 110 accuracy: 0.6494464944649446
At round 110 training accuracy: 0.6838541666666667
At round 110 training loss: 1.060696724789838
gradient difference: 81.57397153071061
At round 111 accuracy: 0.5544280442804428
At round 111 training accuracy: 0.5446875
At round 111 training loss: 1.484777231545498
gradient difference: 105.63467814860873
At round 112 accuracy: 0.6595940959409594
At round 112 training accuracy: 0.6842708333333334
At round 112 training loss: 1.052614542823285
gradient difference: 80.43312778574645
At round 113 accuracy: 0.6577490774907749
At round 113 training accuracy: 0.6875
At round 113 training loss: 1.0523832853945594
gradient difference: 80.42871000594263
At round 114 accuracy: 0.6005535055350554
At round 114 training accuracy: 0.6197916666666666
At round 114 training loss: 1.1820418826397507
gradient difference: 85.4860870300595
At round 115 accuracy: 0.6356088560885609
At round 115 training accuracy: 0.6441666666666667
At round 115 training loss: 1.1330948708532378
gradient difference: 82.38192322263757
At round 116 accuracy: 0.6263837638376384
At round 116 training accuracy: 0.6401041666666667
At round 116 training loss: 1.129835389587097
gradient difference: 84.31010240241012
At round 117 accuracy: 0.6429889298892989
At round 117 training accuracy: 0.6730208333333333
At round 117 training loss: 1.0832593719506016
gradient difference: 81.2217375744556
At round 118 accuracy: 0.6503690036900369
At round 118 training accuracy: 0.6580208333333334
At round 118 training loss: 1.082790581046914
gradient difference: 82.16317707195746
At round 119 accuracy: 0.6208487084870848
At round 119 training accuracy: 0.6101041666666667
At round 119 training loss: 1.2022468895387526
gradient difference: 89.53422426617723
At round 120 accuracy: 0.6503690036900369
At round 120 training accuracy: 0.6675
At round 120 training loss: 1.053397909058258
gradient difference: 80.01459989439589
At round 121 accuracy: 0.6476014760147601
At round 121 training accuracy: 0.6667708333333333
At round 121 training loss: 1.0456081264093517
gradient difference: 81.0067816209678
At round 122 accuracy: 0.6217712177121771
At round 122 training accuracy: 0.610625
At round 122 training loss: 1.1984826110551754
gradient difference: 91.19302838648034
At round 123 accuracy: 0.6180811808118081
At round 123 training accuracy: 0.6401041666666667
At round 123 training loss: 1.0886820292472839
gradient difference: 83.52004748338453
At round 124 accuracy: 0.5747232472324724
At round 124 training accuracy: 0.5897916666666667
At round 124 training loss: 1.2298897091283774
gradient difference: 91.49766571668407
At round 125 accuracy: 0.5756457564575646
At round 125 training accuracy: 0.5875
At round 125 training loss: 1.229738108900686
gradient difference: 91.9634390259535
At round 126 accuracy: 0.5202952029520295
At round 126 training accuracy: 0.5427083333333333
At round 126 training loss: 1.4800015828525648
gradient difference: 101.82417203287704
At round 127 accuracy: 0.507380073800738
At round 127 training accuracy: 0.5290625
At round 127 training loss: 1.697763149907502
gradient difference: 106.48339873877876
At round 128 accuracy: 0.48985239852398527
At round 128 training accuracy: 0.5166666666666667
At round 128 training loss: 2.125359287535151
gradient difference: 111.9087956328183
At round 129 accuracy: 0.48985239852398527
At round 129 training accuracy: 0.5178125
At round 129 training loss: 2.5985012418885405
gradient difference: 111.76323754873299
At round 130 accuracy: 0.5931734317343174
At round 130 training accuracy: 0.6159375
At round 130 training loss: 1.1130809212910633
gradient difference: 84.01951652350967
At round 131 accuracy: 0.6402214022140221
At round 131 training accuracy: 0.6485416666666667
At round 131 training loss: 1.0144633893715218
gradient difference: 77.92843234159254
At round 132 accuracy: 0.6605166051660517
At round 132 training accuracy: 0.681875
At round 132 training loss: 0.9809308768296614
gradient difference: 75.384595840059
At round 133 accuracy: 0.6439114391143912
At round 133 training accuracy: 0.6533333333333333
At round 133 training loss: 1.026146967317909
gradient difference: 79.5568821043174
At round 134 accuracy: 0.6577490774907749
At round 134 training accuracy: 0.6791666666666667
At round 134 training loss: 0.9789508412607635
gradient difference: 75.41931051404829
At round 135 accuracy: 0.6642066420664207
At round 135 training accuracy: 0.6905208333333334
At round 135 training loss: 0.9478500778383265
gradient difference: 72.82283427232898
At round 136 accuracy: 0.6051660516605166
At round 136 training accuracy: 0.6298958333333333
At round 136 training loss: 1.100561746599463
gradient difference: 81.06949086471882
At round 137 accuracy: 0.6107011070110702
At round 137 training accuracy: 0.6370833333333333
At round 137 training loss: 1.0701425593486056
gradient difference: 78.31014328046871
At round 138 accuracy: 0.6476014760147601
At round 138 training accuracy: 0.6570833333333334
At round 138 training loss: 1.0153942279936745
gradient difference: 74.66978491389901
At round 139 accuracy: 0.6632841328413284
At round 139 training accuracy: 0.6944791666666666
At round 139 training loss: 0.9608765157839905
gradient difference: 71.67171927964462
At round 140 accuracy: 0.6706642066420664
At round 140 training accuracy: 0.6883333333333334
At round 140 training loss: 0.9636379961157218
gradient difference: 70.59260941647264
At round 141 accuracy: 0.5747232472324724
At round 141 training accuracy: 0.5907291666666666
At round 141 training loss: 1.2095472530974076
gradient difference: 83.00477574327807
At round 142 accuracy: 0.5959409594095941
At round 142 training accuracy: 0.6096875
At round 142 training loss: 1.135678345002234
gradient difference: 79.65111121205116
At round 143 accuracy: 0.5276752767527675
At round 143 training accuracy: 0.5448958333333334
At round 143 training loss: 1.6150047783615689
gradient difference: 96.09808894801014
At round 144 accuracy: 0.5830258302583026
At round 144 training accuracy: 0.605
At round 144 training loss: 1.144018573767195
gradient difference: 80.2536413564725
At round 145 accuracy: 0.6614391143911439
At round 145 training accuracy: 0.6694791666666666
At round 145 training loss: 0.9746826026247194
gradient difference: 71.5364976892101
At round 146 accuracy: 0.6669741697416974
At round 146 training accuracy: 0.6790625
At round 146 training loss: 0.9399079403017337
gradient difference: 67.124478874563
At round 147 accuracy: 0.6771217712177122
At round 147 training accuracy: 0.7060416666666667
At round 147 training loss: 0.8897582937357947
gradient difference: 64.13222519418916
At round 148 accuracy: 0.5876383763837638
At round 148 training accuracy: 0.6082291666666667
At round 148 training loss: 1.140435135976101
gradient difference: 80.35827942814035
At round 149 accuracy: 0.6669741697416974
At round 149 training accuracy: 0.6895833333333333
At round 149 training loss: 0.9454369515134021
gradient difference: 69.12462181789165
At round 150 accuracy: 0.6734317343173432
At round 150 training accuracy: 0.7057291666666666
At round 150 training loss: 0.9043946700387945
gradient difference: 65.60248093095592
At round 151 accuracy: 0.6439114391143912
At round 151 training accuracy: 0.6271875
At round 151 training loss: 1.1187053354239713
gradient difference: 80.95288457572302
At round 152 accuracy: 0.6642066420664207
At round 152 training accuracy: 0.6977083333333334
At round 152 training loss: 0.9664453246754905
gradient difference: 69.69665654613442
At round 153 accuracy: 0.6752767527675276
At round 153 training accuracy: 0.7059375
At round 153 training loss: 0.9691945330767582
gradient difference: 70.16361518756997
At round 154 accuracy: 0.6752767527675276
At round 154 training accuracy: 0.7023958333333333
At round 154 training loss: 0.9847648895299063
gradient difference: 71.75924088829494
At round 155 accuracy: 0.6143911439114391
At round 155 training accuracy: 0.6319791666666666
At round 155 training loss: 1.1446219137962907
gradient difference: 80.49610577200289
At round 156 accuracy: 0.6734317343173432
At round 156 training accuracy: 0.7022916666666666
At round 156 training loss: 0.9771905006064723
gradient difference: 71.19727605530947
At round 157 accuracy: 0.5535055350553506
At round 157 training accuracy: 0.5794791666666667
At round 157 training loss: 1.3992970068892463
gradient difference: 90.51335321886843
At round 158 accuracy: 0.6743542435424354
At round 158 training accuracy: 0.6919791666666667
At round 158 training loss: 0.9854563065556189
gradient difference: 72.87401741611492
At round 159 accuracy: 0.6614391143911439
At round 159 training accuracy: 0.685
At round 159 training loss: 1.0152543624086927
gradient difference: 72.59091805222702
At round 160 accuracy: 0.6365313653136532
At round 160 training accuracy: 0.6563541666666667
At round 160 training loss: 1.0479114637135838
gradient difference: 76.53364822434625
At round 161 accuracy: 0.6623616236162362
At round 161 training accuracy: 0.693125
At round 161 training loss: 0.9573097698468094
gradient difference: 69.7938677330108
At round 162 accuracy: 0.6854243542435424
At round 162 training accuracy: 0.713125
At round 162 training loss: 0.9053745220135897
gradient difference: 64.37381531810755
At round 163 accuracy: 0.6808118081180812
At round 163 training accuracy: 0.7129166666666666
At round 163 training loss: 0.9322211673545341
gradient difference: 65.8496264390596
At round 164 accuracy: 0.6863468634686347
At round 164 training accuracy: 0.7130208333333333
At round 164 training loss: 0.9117791732742141
gradient difference: 63.36800783090954
At round 165 accuracy: 0.6918819188191881
At round 165 training accuracy: 0.7208333333333333
At round 165 training loss: 0.9184534870429585
gradient difference: 64.17785491076852
At round 166 accuracy: 0.5950184501845018
At round 166 training accuracy: 0.61375
At round 166 training loss: 1.1864080872091776
gradient difference: 80.20185080173451
At round 167 accuracy: 0.5627306273062731
At round 167 training accuracy: 0.5901041666666667
At round 167 training loss: 1.3221684028285865
gradient difference: 84.67915298256938
At round 168 accuracy: 0.6891143911439115
At round 168 training accuracy: 0.72
At round 168 training loss: 0.9177628403374304
gradient difference: 64.26325306989426
At round 169 accuracy: 0.6881918819188192
At round 169 training accuracy: 0.7157291666666666
At round 169 training loss: 0.9182976928229133
gradient difference: 63.034961648131436
At round 170 accuracy: 0.6955719557195572
At round 170 training accuracy: 0.7170833333333333
At round 170 training loss: 0.9116095702769235
gradient difference: 62.90122846281693
At round 171 accuracy: 0.540590405904059
At round 171 training accuracy: 0.5541666666666667
At round 171 training loss: 1.6619875417634224
gradient difference: 94.16723503790466
At round 172 accuracy: 0.544280442804428
At round 172 training accuracy: 0.5638541666666667
At round 172 training loss: 1.5012472869455815
gradient difference: 90.64548555897886
At round 173 accuracy: 0.5452029520295203
At round 173 training accuracy: 0.5647916666666667
At round 173 training loss: 1.438253105545106
gradient difference: 89.40898322395823
At round 174 accuracy: 0.5479704797047971
At round 174 training accuracy: 0.5663541666666667
At round 174 training loss: 1.4618969979478666
gradient difference: 89.53216826959847
At round 175 accuracy: 0.522140221402214
At round 175 training accuracy: 0.5404166666666667
At round 175 training loss: 2.102866545262126
gradient difference: 100.11980210185055
At round 176 accuracy: 0.6706642066420664
At round 176 training accuracy: 0.7011458333333334
At round 176 training loss: 0.920391503291515
gradient difference: 65.02633929042591
At round 177 accuracy: 0.5701107011070111
At round 177 training accuracy: 0.5830208333333333
At round 177 training loss: 1.324390682723994
gradient difference: 83.43447628276432
At round 178 accuracy: 0.5461254612546126
At round 178 training accuracy: 0.5694791666666666
At round 178 training loss: 1.437077187037406
gradient difference: 88.21660468717043
At round 179 accuracy: 0.5267527675276753
At round 179 training accuracy: 0.54875
At round 179 training loss: 1.9090549613333618
gradient difference: 95.54647156777506
At round 180 accuracy: 0.5202952029520295
At round 180 training accuracy: 0.5435416666666667
At round 180 training loss: 2.6855177905689924
gradient difference: 98.55954276480315
At round 181 accuracy: 0.5433579335793358
At round 181 training accuracy: 0.5628125
At round 181 training loss: 1.5386917714572823
gradient difference: 87.8625651326113
At round 182 accuracy: 0.559040590405904
At round 182 training accuracy: 0.580625
At round 182 training loss: 1.3001631108438596
gradient difference: 81.32612339904651
At round 183 accuracy: 0.6964944649446494
At round 183 training accuracy: 0.7188541666666667
At round 183 training loss: 0.8397960597183556
gradient difference: 58.93802382088572
At round 184 accuracy: 0.6752767527675276
At round 184 training accuracy: 0.6804166666666667
At round 184 training loss: 0.9088399424031377
gradient difference: 63.36823672378896
At round 185 accuracy: 0.6678966789667896
At round 185 training accuracy: 0.6571875
At round 185 training loss: 0.9660853845874469
gradient difference: 67.8739821798973
At round 186 accuracy: 0.6881918819188192
At round 186 training accuracy: 0.7059375
At round 186 training loss: 0.8454554658134779
gradient difference: 58.47082424259011
At round 187 accuracy: 0.6992619926199262
At round 187 training accuracy: 0.7282291666666667
At round 187 training loss: 0.8409057388547808
gradient difference: 57.90443731296321
At round 188 accuracy: 0.6863468634686347
At round 188 training accuracy: 0.7104166666666667
At round 188 training loss: 0.8447750184126198
gradient difference: 57.75694538843654
At round 189 accuracy: 0.6881918819188192
At round 189 training accuracy: 0.7179166666666666
At round 189 training loss: 0.8590089064277708
gradient difference: 58.83100066304607
At round 190 accuracy: 0.6808118081180812
At round 190 training accuracy: 0.6984375
At round 190 training loss: 0.8896077039279043
gradient difference: 60.25284193284509
At round 191 accuracy: 0.6549815498154982
At round 191 training accuracy: 0.676875
At round 191 training loss: 0.9634827525665363
gradient difference: 64.93129319420095
At round 192 accuracy: 0.6143911439114391
At round 192 training accuracy: 0.6289583333333333
At round 192 training loss: 1.0975522823631763
gradient difference: 73.5596802509263
At round 193 accuracy: 0.6964944649446494
At round 193 training accuracy: 0.7260416666666667
At round 193 training loss: 0.8698643405300875
gradient difference: 59.79444538597834
At round 194 accuracy: 0.6974169741697417
At round 194 training accuracy: 0.7222916666666667
At round 194 training loss: 0.8922966288309544
gradient difference: 61.480600511231906
At round 195 accuracy: 0.6937269372693727
At round 195 training accuracy: 0.7172916666666667
At round 195 training loss: 0.9179661836785574
gradient difference: 63.02404193360984
At round 196 accuracy: 0.6494464944649446
At round 196 training accuracy: 0.6697916666666667
At round 196 training loss: 1.0102241846111915
gradient difference: 68.19410870817953
At round 197 accuracy: 0.6134686346863468
At round 197 training accuracy: 0.6263541666666667
At round 197 training loss: 1.1202759271487595
gradient difference: 76.39630517728963
At round 198 accuracy: 0.5452029520295203
At round 198 training accuracy: 0.5685416666666666
At round 198 training loss: 1.4849409003198768
gradient difference: 90.54709050618058
At round 199 accuracy: 0.6964944649446494
At round 199 training accuracy: 0.7179166666666666
At round 199 training loss: 0.8874932444902758
gradient difference: 62.97903887006084
At round 200 accuracy: 0.672509225092251
At round 200 training accuracy: 0.6880208333333333
