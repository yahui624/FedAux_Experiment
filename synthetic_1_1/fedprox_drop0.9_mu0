Arguments:
	       batch_size : 10
	clients_per_round : 10
	          dataset : synthetic_1_1
	     drop_percent : 0.9
	       eval_every : 1
	    learning_rate : 0.01
	            model : mclr
	     model_params : (10,)
	               mu : 0.0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedprox
	             seed : 0
Using Federated prox to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/5.44k flops)
  dense/kernel/Regularizer/l2_regularizer (1/1.80k flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (1.80k/1.80k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  PGD/update_dense/kernel/AssignSub (600/600 flops)
  PGD/update_dense/kernel/mul (600/600 flops)
  PGD/update_dense/kernel/mul_1 (600/600 flops)
  PGD/update_dense/kernel/sub (600/600 flops)
  PGD/update_dense/bias/AssignSub (10/10 flops)
  PGD/update_dense/bias/mul (10/10 flops)
  PGD/update_dense/bias/mul_1 (10/10 flops)
  PGD/update_dense/bias/sub (10/10 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
30 Clients in Total
Training with 10 workers ---
At round 0 accuracy: 0.3016605166051661
At round 0 training accuracy: 0.28739583333333335
At round 0 training loss: 2.814805432880918
gradient difference: 116.13141207625425
At round 1 accuracy: 0.36808118081180813
At round 1 training accuracy: 0.346875
At round 1 training loss: 3.2068264486889047
gradient difference: 112.901114031309
At round 2 accuracy: 0.33210332103321033
At round 2 training accuracy: 0.3258333333333333
At round 2 training loss: 3.559353797659278
gradient difference: 113.47902570366094
At round 3 accuracy: 0.35885608856088563
At round 3 training accuracy: 0.350625
At round 3 training loss: 2.990572995568315
gradient difference: 109.98396222833262
At round 4 accuracy: 0.496309963099631
At round 4 training accuracy: 0.523125
At round 4 training loss: 1.7120688133314252
gradient difference: 89.20051158368892
At round 5 accuracy: 0.48800738007380073
At round 5 training accuracy: 0.47729166666666667
At round 5 training loss: 2.1532163462539513
gradient difference: 107.3005844017287
At round 6 accuracy: 0.5350553505535055
At round 6 training accuracy: 0.5442708333333334
At round 6 training loss: 1.919336448246613
gradient difference: 98.82365087894367
At round 7 accuracy: 0.49538745387453875
At round 7 training accuracy: 0.48114583333333333
At round 7 training loss: 1.7246644285321235
gradient difference: 104.69551541643288
At round 8 accuracy: 0.551660516605166
At round 8 training accuracy: 0.5497916666666667
At round 8 training loss: 1.5289672044540445
gradient difference: 95.86358217954846
At round 9 accuracy: 0.5525830258302583
At round 9 training accuracy: 0.5733333333333334
At round 9 training loss: 1.7036330718981723
gradient difference: 99.95233500303685
At round 10 accuracy: 0.5507380073800738
At round 10 training accuracy: 0.5436458333333334
At round 10 training loss: 1.5525836368401846
gradient difference: 101.16132161874457
At round 11 accuracy: 0.5636531365313653
At round 11 training accuracy: 0.566875
At round 11 training loss: 1.4092638334073126
gradient difference: 96.07373819390885
At round 12 accuracy: 0.5839483394833949
At round 12 training accuracy: 0.6138541666666667
At round 12 training loss: 1.5132657687117657
gradient difference: 96.7468569490528
At round 13 accuracy: 0.5166051660516605
At round 13 training accuracy: 0.534375
At round 13 training loss: 1.6877355190056065
gradient difference: 107.38132305393566
At round 14 accuracy: 0.5599630996309963
At round 14 training accuracy: 0.5886458333333333
At round 14 training loss: 1.7309228757427384
gradient difference: 105.10364045511567
At round 15 accuracy: 0.5738007380073801
At round 15 training accuracy: 0.61
At round 15 training loss: 1.777025866250818
gradient difference: 105.97803001366997
At round 16 accuracy: 0.45940959409594095
At round 16 training accuracy: 0.4847916666666667
At round 16 training loss: 2.071865601018071
gradient difference: 122.65511749206884
At round 17 accuracy: 0.4446494464944649
At round 17 training accuracy: 0.4659375
At round 17 training loss: 2.079539525695145
gradient difference: 124.13111878510932
At round 18 accuracy: 0.4566420664206642
At round 18 training accuracy: 0.4816666666666667
At round 18 training loss: 1.8082097010252376
gradient difference: 116.6245186130612
At round 19 accuracy: 0.43726937269372695
At round 19 training accuracy: 0.4588541666666667
At round 19 training loss: 1.8828250725008546
gradient difference: 119.98394107631471
At round 20 accuracy: 0.4603321033210332
At round 20 training accuracy: 0.4866666666666667
At round 20 training loss: 1.654401021550099
gradient difference: 113.74664283330145
At round 21 accuracy: 0.5018450184501845
At round 21 training accuracy: 0.5236458333333334
At round 21 training loss: 1.5211464581793794
gradient difference: 106.12332984547271
At round 22 accuracy: 0.46309963099630996
At round 22 training accuracy: 0.49083333333333334
At round 22 training loss: 1.7339859203388914
gradient difference: 113.58935102761407
At round 23 accuracy: 0.5562730627306273
At round 23 training accuracy: 0.5840625
At round 23 training loss: 1.4585291549159836
gradient difference: 105.30045730383898
At round 24 accuracy: 0.5793357933579336
At round 24 training accuracy: 0.604375
At round 24 training loss: 1.4848796873477599
gradient difference: 106.96503711152921
At round 25 accuracy: 0.5599630996309963
At round 25 training accuracy: 0.5511458333333333
At round 25 training loss: 1.5205671586530904
gradient difference: 114.54476078064656
At round 26 accuracy: 0.540590405904059
At round 26 training accuracy: 0.5457291666666667
At round 26 training loss: 1.4887686533201485
gradient difference: 113.71660043431851
At round 27 accuracy: 0.5055350553505535
At round 27 training accuracy: 0.5070833333333333
At round 27 training loss: 1.6313050947586696
gradient difference: 123.05262880955163
At round 28 accuracy: 0.5857933579335793
At round 28 training accuracy: 0.6260416666666667
At round 28 training loss: 1.4105511158239097
gradient difference: 101.94084824164064
At round 29 accuracy: 0.5894833948339483
At round 29 training accuracy: 0.6230208333333334
At round 29 training loss: 1.361138959005475
gradient difference: 101.55563952820434
At round 30 accuracy: 0.5922509225092251
At round 30 training accuracy: 0.6355208333333333
At round 30 training loss: 1.316196772319575
gradient difference: 99.00468070846527
At round 31 accuracy: 0.5839483394833949
At round 31 training accuracy: 0.6207291666666667
At round 31 training loss: 1.4600732375867664
gradient difference: 105.81957498976936
At round 32 accuracy: 0.5802583025830258
At round 32 training accuracy: 0.6192708333333333
At round 32 training loss: 1.530777144379293
gradient difference: 107.6176465481577
At round 33 accuracy: 0.5701107011070111
At round 33 training accuracy: 0.5834375
At round 33 training loss: 1.6455014033957074
gradient difference: 115.8600305227512
At round 34 accuracy: 0.5710332103321033
At round 34 training accuracy: 0.5790625
At round 34 training loss: 1.673513227008904
gradient difference: 116.9878541593691
At round 35 accuracy: 0.584870848708487
At round 35 training accuracy: 0.6088541666666667
At round 35 training loss: 1.6718502911211301
gradient difference: 113.52808965566145
At round 36 accuracy: 0.518450184501845
At round 36 training accuracy: 0.5072916666666667
At round 36 training loss: 1.8473803480931867
gradient difference: 129.5440101851811
At round 37 accuracy: 0.5673431734317343
At round 37 training accuracy: 0.5779166666666666
At round 37 training loss: 1.6880901428653547
gradient difference: 117.20765924368423
At round 38 accuracy: 0.4575645756457565
At round 38 training accuracy: 0.4578125
At round 38 training loss: 2.236085024724404
gradient difference: 145.48111104032535
At round 39 accuracy: 0.4483394833948339
At round 39 training accuracy: 0.44916666666666666
At round 39 training loss: 2.4044471496467787
gradient difference: 149.49893377130363
At round 40 accuracy: 0.5959409594095941
At round 40 training accuracy: 0.6046875
At round 40 training loss: 1.5381424308909724
gradient difference: 111.49531700646932
At round 41 accuracy: 0.5811808118081181
At round 41 training accuracy: 0.5805208333333334
At round 41 training loss: 1.6516561407921835
gradient difference: 116.9310047706734
At round 42 accuracy: 0.5959409594095941
At round 42 training accuracy: 0.6022916666666667
At round 42 training loss: 1.6019539356076469
gradient difference: 113.26168002146295
At round 43 accuracy: 0.6005535055350554
At round 43 training accuracy: 0.6373958333333334
At round 43 training loss: 1.5725626983757441
gradient difference: 108.01220510953114
At round 44 accuracy: 0.5968634686346863
At round 44 training accuracy: 0.6148958333333333
At round 44 training loss: 1.5335682468364635
gradient difference: 110.81824640018995
At round 45 accuracy: 0.466789667896679
At round 45 training accuracy: 0.48802083333333335
At round 45 training loss: 2.0557441815175115
gradient difference: 128.02322004376532
At round 46 accuracy: 0.488929889298893
At round 46 training accuracy: 0.5071875
At round 46 training loss: 1.8875593418317536
gradient difference: 123.05371181562847
At round 47 accuracy: 0.48247232472324725
At round 47 training accuracy: 0.5060416666666666
At round 47 training loss: 1.8914369120402261
gradient difference: 124.07588106555843
At round 48 accuracy: 0.6245387453874539
At round 48 training accuracy: 0.6577083333333333
At round 48 training loss: 1.3635954517824576
gradient difference: 101.58427759953179
At round 49 accuracy: 0.6088560885608856
At round 49 training accuracy: 0.6440625
At round 49 training loss: 1.43466401170784
gradient difference: 104.33330189792528
At round 50 accuracy: 0.6236162361623616
At round 50 training accuracy: 0.6469791666666667
At round 50 training loss: 1.460545559572056
gradient difference: 105.02431399744145
At round 51 accuracy: 0.6162361623616236
At round 51 training accuracy: 0.6263541666666667
At round 51 training loss: 1.465957527103213
gradient difference: 107.09884471054698
At round 52 accuracy: 0.6060885608856088
At round 52 training accuracy: 0.6321875
At round 52 training loss: 1.4890148427104577
gradient difference: 104.80675320340005
At round 53 accuracy: 0.6282287822878229
At round 53 training accuracy: 0.6501041666666667
At round 53 training loss: 1.4454590844300885
gradient difference: 104.0265224545061
At round 54 accuracy: 0.6254612546125461
At round 54 training accuracy: 0.6473958333333333
At round 54 training loss: 1.469059075343733
gradient difference: 105.21480086205445
At round 55 accuracy: 0.6208487084870848
At round 55 training accuracy: 0.6483333333333333
At round 55 training loss: 1.432713556306747
gradient difference: 101.80767510110739
At round 56 accuracy: 0.6190036900369004
At round 56 training accuracy: 0.6373958333333334
At round 56 training loss: 1.4064236889003465
gradient difference: 102.61292432941349
At round 57 accuracy: 0.6143911439114391
At round 57 training accuracy: 0.6202083333333334
At round 57 training loss: 1.4128013659703236
gradient difference: 103.77816268181947
At round 58 accuracy: 0.6143911439114391
At round 58 training accuracy: 0.6178125
At round 58 training loss: 1.401488834110399
gradient difference: 103.43577691173506
At round 59 accuracy: 0.6291512915129152
At round 59 training accuracy: 0.6608333333333334
At round 59 training loss: 1.3707339962602902
gradient difference: 97.45729514269603
At round 60 accuracy: 0.6356088560885609
At round 60 training accuracy: 0.6623958333333333
At round 60 training loss: 1.3137466417547936
gradient difference: 94.34900212505998
At round 61 accuracy: 0.6107011070110702
At round 61 training accuracy: 0.6052083333333333
At round 61 training loss: 1.3853823306799555
gradient difference: 103.45011693232371
At round 62 accuracy: 0.6190036900369004
At round 62 training accuracy: 0.61125
At round 62 training loss: 1.3459348909805218
gradient difference: 98.95098144768326
At round 63 accuracy: 0.6190036900369004
At round 63 training accuracy: 0.6075
At round 63 training loss: 1.3325804654322564
gradient difference: 99.16711158283861
At round 64 accuracy: 0.6383763837638377
At round 64 training accuracy: 0.6471875
At round 64 training loss: 1.2433710912739238
gradient difference: 93.16661859891019
At round 65 accuracy: 0.6383763837638377
At round 65 training accuracy: 0.6496875
At round 65 training loss: 1.279049641711948
gradient difference: 95.36519399228236
At round 66 accuracy: 0.6070110701107011
At round 66 training accuracy: 0.5897916666666667
At round 66 training loss: 1.3905343334982172
gradient difference: 104.14057254423068
At round 67 accuracy: 0.6199261992619927
At round 67 training accuracy: 0.6141666666666666
At round 67 training loss: 1.295872080201904
gradient difference: 98.40784815053574
At round 68 accuracy: 0.6429889298892989
At round 68 training accuracy: 0.6711458333333333
At round 68 training loss: 1.1178657588455827
gradient difference: 85.8500010436082
At round 69 accuracy: 0.6429889298892989
At round 69 training accuracy: 0.6730208333333333
At round 69 training loss: 1.0959216886308665
gradient difference: 84.28512647610133
At round 70 accuracy: 0.6282287822878229
At round 70 training accuracy: 0.6372916666666667
At round 70 training loss: 1.1697457592887803
gradient difference: 91.39228864633587
At round 71 accuracy: 0.6319188191881919
At round 71 training accuracy: 0.6461458333333333
At round 71 training loss: 1.200074873495226
gradient difference: 92.80165695703893
At round 72 accuracy: 0.6429889298892989
At round 72 training accuracy: 0.6701041666666666
At round 72 training loss: 1.1770278386600936
gradient difference: 89.1104697973095
At round 73 accuracy: 0.6337638376383764
At round 73 training accuracy: 0.6441666666666667
At round 73 training loss: 1.188403315800242
gradient difference: 91.91665664624878
At round 74 accuracy: 0.6116236162361623
At round 74 training accuracy: 0.5957291666666666
At round 74 training loss: 1.2936303354039167
gradient difference: 99.6988820759801
At round 75 accuracy: 0.6273062730627307
At round 75 training accuracy: 0.6448958333333333
At round 75 training loss: 1.1016226308901484
gradient difference: 83.46374162243023
At round 76 accuracy: 0.6429889298892989
At round 76 training accuracy: 0.6714583333333334
At round 76 training loss: 1.0932567843204986
gradient difference: 84.25486871703677
At round 77 accuracy: 0.6263837638376384
At round 77 training accuracy: 0.6429166666666667
At round 77 training loss: 1.123870017064425
gradient difference: 84.74027681633625
At round 78 accuracy: 0.6402214022140221
At round 78 training accuracy: 0.6726041666666667
At round 78 training loss: 1.1110113107878714
gradient difference: 84.19526351111281
At round 79 accuracy: 0.6411439114391144
At round 79 training accuracy: 0.6513541666666667
At round 79 training loss: 1.1673865269760912
gradient difference: 88.95047143412037
At round 80 accuracy: 0.6309963099630996
At round 80 training accuracy: 0.6351041666666667
At round 80 training loss: 1.1836616253868366
gradient difference: 91.47059540185433
At round 81 accuracy: 0.5608856088560885
At round 81 training accuracy: 0.5803125
At round 81 training loss: 1.3067882810393348
gradient difference: 93.82361562292327
At round 82 accuracy: 0.6503690036900369
At round 82 training accuracy: 0.6711458333333333
At round 82 training loss: 1.1052525211218744
gradient difference: 84.81260866304432
At round 83 accuracy: 0.6439114391143912
At round 83 training accuracy: 0.6767708333333333
At round 83 training loss: 1.0991889492701739
gradient difference: 83.41007805143205
At round 84 accuracy: 0.6466789667896679
At round 84 training accuracy: 0.6771875
At round 84 training loss: 1.099207837426414
gradient difference: 82.98179565452581
At round 85 accuracy: 0.6402214022140221
At round 85 training accuracy: 0.6689583333333333
At round 85 training loss: 1.1164481080618376
gradient difference: 83.66160753563564
At round 86 accuracy: 0.6540590405904059
At round 86 training accuracy: 0.6786458333333333
At round 86 training loss: 1.08681502245677
gradient difference: 77.715730379051
At round 87 accuracy: 0.6494464944649446
At round 87 training accuracy: 0.6736458333333334
At round 87 training loss: 1.0829697516001762
gradient difference: 76.45115089212904
At round 88 accuracy: 0.5922509225092251
At round 88 training accuracy: 0.615625
At round 88 training loss: 1.1683915176521986
gradient difference: 83.93029921228785
At round 89 accuracy: 0.6051660516605166
At round 89 training accuracy: 0.6258333333333334
At round 89 training loss: 1.131379946215699
gradient difference: 81.59500326761064
At round 90 accuracy: 0.6217712177121771
At round 90 training accuracy: 0.6383333333333333
At round 90 training loss: 1.0857334781748553
gradient difference: 79.92105679911225
At round 91 accuracy: 0.6125461254612546
At round 91 training accuracy: 0.6319791666666666
At round 91 training loss: 1.071301613813266
gradient difference: 77.57303534120199
At round 92 accuracy: 0.6669741697416974
At round 92 training accuracy: 0.6938541666666667
At round 92 training loss: 0.9565532872018715
gradient difference: 71.80681414476746
At round 93 accuracy: 0.6356088560885609
At round 93 training accuracy: 0.6269791666666666
At round 93 training loss: 1.072214471086239
gradient difference: 82.28161333467081
At round 94 accuracy: 0.6632841328413284
At round 94 training accuracy: 0.66875
At round 94 training loss: 0.9588804265328993
gradient difference: 70.8252610712582
At round 95 accuracy: 0.6559040590405905
At round 95 training accuracy: 0.6448958333333333
At round 95 training loss: 0.9974220842309296
gradient difference: 73.39019609285596
At round 96 accuracy: 0.6245387453874539
At round 96 training accuracy: 0.6086458333333333
At round 96 training loss: 1.0972056147859741
gradient difference: 80.74065299124612
At round 97 accuracy: 0.6439114391143912
At round 97 training accuracy: 0.6408333333333334
At round 97 training loss: 0.9946055938738088
gradient difference: 75.1203296563834
At round 98 accuracy: 0.6642066420664207
At round 98 training accuracy: 0.6935416666666666
At round 98 training loss: 0.9264247488416731
gradient difference: 70.76602845920935
At round 99 accuracy: 0.6503690036900369
At round 99 training accuracy: 0.6785416666666667
At round 99 training loss: 0.9876997648272663
gradient difference: 74.56646586649481
At round 100 accuracy: 0.665129151291513
At round 100 training accuracy: 0.6815625
At round 100 training loss: 0.9905007845380654
gradient difference: 76.05718563686084
At round 101 accuracy: 0.6476014760147601
At round 101 training accuracy: 0.6473958333333333
At round 101 training loss: 1.0468308306112886
gradient difference: 81.7462904060969
At round 102 accuracy: 0.6346863468634686
At round 102 training accuracy: 0.6283333333333333
At round 102 training loss: 1.0821442873124034
gradient difference: 83.58563687042486
At round 103 accuracy: 0.6697416974169742
At round 103 training accuracy: 0.6866666666666666
At round 103 training loss: 0.9465486074549456
gradient difference: 74.2811278940563
At round 104 accuracy: 0.6429889298892989
At round 104 training accuracy: 0.6427083333333333
At round 104 training loss: 1.0677009992549817
gradient difference: 83.55242791101857
At round 105 accuracy: 0.6642066420664207
At round 105 training accuracy: 0.6907291666666666
At round 105 training loss: 1.0107934614177794
gradient difference: 76.83494991950192
At round 106 accuracy: 0.6669741697416974
At round 106 training accuracy: 0.6852083333333333
At round 106 training loss: 1.000239736114939
gradient difference: 77.3934683896455
At round 107 accuracy: 0.6457564575645757
At round 107 training accuracy: 0.6465625
At round 107 training loss: 1.0664470877187948
gradient difference: 83.34995951382082
At round 108 accuracy: 0.6605166051660517
At round 108 training accuracy: 0.6747916666666667
At round 108 training loss: 0.9858389767011007
gradient difference: 78.40453339887611
At round 109 accuracy: 0.6632841328413284
At round 109 training accuracy: 0.6854166666666667
At round 109 training loss: 0.9949819411182155
gradient difference: 78.22745393857645
At round 110 accuracy: 0.6642066420664207
At round 110 training accuracy: 0.675625
At round 110 training loss: 1.000963719971478
gradient difference: 79.00400332328391
At round 111 accuracy: 0.5913284132841329
At round 111 training accuracy: 0.5721875
At round 111 training loss: 1.2971389027902236
gradient difference: 96.14948056620453
At round 112 accuracy: 0.6512915129151291
At round 112 training accuracy: 0.6566666666666666
At round 112 training loss: 1.0290840841038154
gradient difference: 80.26395971295197
At round 113 accuracy: 0.6688191881918819
At round 113 training accuracy: 0.676875
At round 113 training loss: 0.9939124637376517
gradient difference: 78.29812682903065
At round 114 accuracy: 0.6586715867158671
At round 114 training accuracy: 0.6741666666666667
At round 114 training loss: 0.9866614290497576
gradient difference: 74.48004647501901
At round 115 accuracy: 0.6771217712177122
At round 115 training accuracy: 0.6936458333333333
At round 115 training loss: 0.976864899971212
gradient difference: 75.18507206764392
At round 116 accuracy: 0.6660516605166051
At round 116 training accuracy: 0.6896875
At round 116 training loss: 0.9801645118789747
gradient difference: 77.47221216532849
At round 117 accuracy: 0.665129151291513
At round 117 training accuracy: 0.6871875
At round 117 training loss: 1.0093358885341635
gradient difference: 79.24791634557737
At round 118 accuracy: 0.6263837638376384
At round 118 training accuracy: 0.61375
At round 118 training loss: 1.1560644332831727
gradient difference: 89.12376695797685
At round 119 accuracy: 0.6005535055350554
At round 119 training accuracy: 0.5884375
At round 119 training loss: 1.242980587844116
gradient difference: 93.468773842539
At round 120 accuracy: 0.6374538745387454
At round 120 training accuracy: 0.639375
At round 120 training loss: 1.0680816286693637
gradient difference: 83.09964170934067
At round 121 accuracy: 0.6180811808118081
At round 121 training accuracy: 0.6047916666666666
At round 121 training loss: 1.1687357000742729
gradient difference: 90.5473877014168
At round 122 accuracy: 0.5793357933579336
At round 122 training accuracy: 0.5735416666666666
At round 122 training loss: 1.3244401038438083
gradient difference: 99.00321906157441
At round 123 accuracy: 0.6734317343173432
At round 123 training accuracy: 0.7028125
At round 123 training loss: 0.9175098420741657
gradient difference: 73.00161875684404
At round 124 accuracy: 0.6494464944649446
At round 124 training accuracy: 0.680625
At round 124 training loss: 0.9468495118881887
gradient difference: 74.90517143537413
At round 125 accuracy: 0.6457564575645757
At round 125 training accuracy: 0.6621875
At round 125 training loss: 0.9787120110883067
gradient difference: 77.16568383724756
At round 126 accuracy: 0.5691881918819188
At round 126 training accuracy: 0.5886458333333333
At round 126 training loss: 1.1716700752669325
gradient difference: 87.72584987451314
At round 127 accuracy: 0.540590405904059
At round 127 training accuracy: 0.5634375
At round 127 training loss: 1.3225631608146553
gradient difference: 93.62635256839366
At round 128 accuracy: 0.5101476014760148
At round 128 training accuracy: 0.5305208333333333
At round 128 training loss: 1.6807394495978951
gradient difference: 102.84670765900607
At round 129 accuracy: 0.496309963099631
At round 129 training accuracy: 0.5209375
At round 129 training loss: 2.2781764627372225
gradient difference: 106.46556235939104
At round 130 accuracy: 0.6448339483394834
At round 130 training accuracy: 0.6775
At round 130 training loss: 0.9147014849695067
gradient difference: 72.71699923938603
At round 131 accuracy: 0.6605166051660517
At round 131 training accuracy: 0.6934375
At round 131 training loss: 0.8858614101695518
gradient difference: 70.96083817388013
At round 132 accuracy: 0.6632841328413284
At round 132 training accuracy: 0.6866666666666666
At round 132 training loss: 0.9238739794259891
gradient difference: 73.2636795559731
At round 133 accuracy: 0.6466789667896679
At round 133 training accuracy: 0.6553125
At round 133 training loss: 0.9739134357217699
gradient difference: 77.74956215925067
At round 134 accuracy: 0.6605166051660517
At round 134 training accuracy: 0.6777083333333334
At round 134 training loss: 0.9299209186062217
gradient difference: 73.79182102143763
At round 135 accuracy: 0.6660516605166051
At round 135 training accuracy: 0.688125
At round 135 training loss: 0.9059926756797358
gradient difference: 71.38925340461637
At round 136 accuracy: 0.6180811808118081
At round 136 training accuracy: 0.6447916666666667
At round 136 training loss: 1.007044160372267
gradient difference: 76.4971827718329
At round 137 accuracy: 0.6060885608856088
At round 137 training accuracy: 0.6291666666666667
At round 137 training loss: 1.0451150033343584
gradient difference: 77.87799974445277
At round 138 accuracy: 0.6568265682656826
At round 138 training accuracy: 0.6716666666666666
At round 138 training loss: 0.9379105320821206
gradient difference: 71.19034543394368
At round 139 accuracy: 0.6402214022140221
At round 139 training accuracy: 0.656875
At round 139 training loss: 0.9920443735131994
gradient difference: 74.62637072873405
At round 140 accuracy: 0.6614391143911439
At round 140 training accuracy: 0.6952083333333333
At round 140 training loss: 0.9125297239003703
gradient difference: 68.68655817145881
At round 141 accuracy: 0.6023985239852399
At round 141 training accuracy: 0.6161458333333333
At round 141 training loss: 1.07551169424473
gradient difference: 77.6952462024597
At round 142 accuracy: 0.6171586715867159
At round 142 training accuracy: 0.6398958333333333
At round 142 training loss: 0.9994670332875103
gradient difference: 73.80014647839181
At round 143 accuracy: 0.5470479704797048
At round 143 training accuracy: 0.5679166666666666
At round 143 training loss: 1.3423067341605202
gradient difference: 88.46153856559071
At round 144 accuracy: 0.6116236162361623
At round 144 training accuracy: 0.6266666666666667
At round 144 training loss: 1.0173355857577795
gradient difference: 74.29128515939207
At round 145 accuracy: 0.6817343173431735
At round 145 training accuracy: 0.7128125
At round 145 training loss: 0.8227734352399906
gradient difference: 63.02392193125004
At round 146 accuracy: 0.6881918819188192
At round 146 training accuracy: 0.7201041666666667
At round 146 training loss: 0.8050147231357793
gradient difference: 60.03429671503508
At round 147 accuracy: 0.6955719557195572
At round 147 training accuracy: 0.73
At round 147 training loss: 0.7919742020731791
gradient difference: 59.401922055845695
At round 148 accuracy: 0.6522140221402214
At round 148 training accuracy: 0.6771875
At round 148 training loss: 0.885132023083667
gradient difference: 65.75942483754463
At round 149 accuracy: 0.6946494464944649
At round 149 training accuracy: 0.7220833333333333
At round 149 training loss: 0.8116886297318463
gradient difference: 61.45409696423917
At round 150 accuracy: 0.6955719557195572
At round 150 training accuracy: 0.7234375
At round 150 training loss: 0.8062721042893827
gradient difference: 59.16642454402596
At round 151 accuracy: 0.7001845018450185
At round 151 training accuracy: 0.7227083333333333
At round 151 training loss: 0.8153673864544059
gradient difference: 59.703934903297885
At round 152 accuracy: 0.6798892988929889
At round 152 training accuracy: 0.6798958333333334
At round 152 training loss: 0.9167927711596713
gradient difference: 68.12428110005025
At round 153 accuracy: 0.6845018450184502
At round 153 training accuracy: 0.6919791666666667
At round 153 training loss: 0.912971668386211
gradient difference: 68.3069446730961
At round 154 accuracy: 0.6900369003690037
At round 154 training accuracy: 0.7042708333333333
At round 154 training loss: 0.9029032243896896
gradient difference: 67.66371078248532
At round 155 accuracy: 0.6891143911439115
At round 155 training accuracy: 0.7180208333333333
At round 155 training loss: 0.8631463090299318
gradient difference: 64.75113523806353
At round 156 accuracy: 0.6706642066420664
At round 156 training accuracy: 0.6866666666666666
At round 156 training loss: 0.9324559852915506
gradient difference: 68.86690428297305
At round 157 accuracy: 0.5461254612546126
At round 157 training accuracy: 0.571875
At round 157 training loss: 1.4256681744707749
gradient difference: 89.31371695187599
At round 158 accuracy: 0.698339483394834
At round 158 training accuracy: 0.718125
At round 158 training loss: 0.8514022953063249
gradient difference: 64.51357831489595
At round 159 accuracy: 0.6937269372693727
At round 159 training accuracy: 0.716875
At round 159 training loss: 0.8705491540720687
gradient difference: 65.63692225924255
At round 160 accuracy: 0.6881918819188192
At round 160 training accuracy: 0.7154166666666667
At round 160 training loss: 0.8511052036983893
gradient difference: 65.96946862453679
At round 161 accuracy: 0.6937269372693727
At round 161 training accuracy: 0.7117708333333334
At round 161 training loss: 0.8502531737585862
gradient difference: 65.37734559480238
At round 162 accuracy: 0.6752767527675276
At round 162 training accuracy: 0.6801041666666666
At round 162 training loss: 0.8999726009182631
gradient difference: 66.4881529640687
At round 163 accuracy: 0.6771217712177122
At round 163 training accuracy: 0.6698958333333334
At round 163 training loss: 0.9320918806673338
gradient difference: 68.76388602675479
At round 164 accuracy: 0.7001845018450185
At round 164 training accuracy: 0.7048958333333334
At round 164 training loss: 0.8498831399405996
gradient difference: 62.428927619862385
At round 165 accuracy: 0.7001845018450185
At round 165 training accuracy: 0.7177083333333333
At round 165 training loss: 0.8443362984930476
gradient difference: 61.34808736286886
At round 166 accuracy: 0.5959409594095941
At round 166 training accuracy: 0.6129166666666667
At round 166 training loss: 1.1446151935045297
gradient difference: 78.87198502358919
At round 167 accuracy: 0.5682656826568265
At round 167 training accuracy: 0.595
At round 167 training loss: 1.2448140261275693
gradient difference: 81.52826458353456
At round 168 accuracy: 0.7011070110701108
At round 168 training accuracy: 0.7263541666666666
At round 168 training loss: 0.8218897530001898
gradient difference: 60.00354488639509
At round 169 accuracy: 0.6881918819188192
At round 169 training accuracy: 0.7189583333333334
At round 169 training loss: 0.8298278926437099
gradient difference: 59.46303269254497
At round 170 accuracy: 0.6918819188191881
At round 170 training accuracy: 0.7188541666666667
At round 170 training loss: 0.82681005857264
gradient difference: 59.96783437307953
At round 171 accuracy: 0.5479704797047971
At round 171 training accuracy: 0.5684375
At round 171 training loss: 1.4263058161083608
gradient difference: 86.58616214866
At round 172 accuracy: 0.5479704797047971
At round 172 training accuracy: 0.5735416666666666
At round 172 training loss: 1.3902928599653144
gradient difference: 84.99813836642531
At round 173 accuracy: 0.5581180811808119
At round 173 training accuracy: 0.5825
At round 173 training loss: 1.2857209182359899
gradient difference: 82.28827929376467
At round 174 accuracy: 0.5654981549815498
At round 174 training accuracy: 0.5883333333333334
At round 174 training loss: 1.2637862671756497
gradient difference: 81.29294515218662
At round 175 accuracy: 0.5369003690036901
At round 175 training accuracy: 0.5557291666666667
At round 175 training loss: 1.8530221549794077
gradient difference: 92.59838031807031
At round 176 accuracy: 0.683579335793358
At round 176 training accuracy: 0.7151041666666667
At round 176 training loss: 0.7940569917764515
gradient difference: 57.49892761255737
At round 177 accuracy: 0.6964944649446494
At round 177 training accuracy: 0.7047916666666667
At round 177 training loss: 0.8114492648032804
gradient difference: 56.06593181854294
At round 178 accuracy: 0.6559040590405905
At round 178 training accuracy: 0.6792708333333334
At round 178 training loss: 0.8608446972786138
gradient difference: 59.783774965150464
At round 179 accuracy: 0.6190036900369004
At round 179 training accuracy: 0.6389583333333333
At round 179 training loss: 0.9875270158688848
gradient difference: 66.58962191762197
At round 180 accuracy: 0.5525830258302583
At round 180 training accuracy: 0.5742708333333333
At round 180 training loss: 1.5546131917523842
gradient difference: 84.42838277326125
At round 181 accuracy: 0.6365313653136532
At round 181 training accuracy: 0.6495833333333333
At round 181 training loss: 0.9397847800794988
gradient difference: 62.53468802370024
At round 182 accuracy: 0.6374538745387454
At round 182 training accuracy: 0.64875
At round 182 training loss: 0.9361290922823051
gradient difference: 62.70925133900999
At round 183 accuracy: 0.7112546125461254
At round 183 training accuracy: 0.7416666666666667
At round 183 training loss: 0.7232365212403238
gradient difference: 49.69582141300115
At round 184 accuracy: 0.6974169741697417
At round 184 training accuracy: 0.7194791666666667
At round 184 training loss: 0.7561953388868521
gradient difference: 52.97895579091343
At round 185 accuracy: 0.6872693726937269
At round 185 training accuracy: 0.69875
At round 185 training loss: 0.7946877772655959
gradient difference: 55.711573870020196
At round 186 accuracy: 0.7084870848708487
At round 186 training accuracy: 0.7329166666666667
At round 186 training loss: 0.7324810510237391
gradient difference: 50.56384884038716
At round 187 accuracy: 0.6955719557195572
At round 187 training accuracy: 0.7192708333333333
At round 187 training loss: 0.782666701041162
gradient difference: 55.10775009949562
At round 188 accuracy: 0.7020295202952029
At round 188 training accuracy: 0.7125
At round 188 training loss: 0.7765561228881901
gradient difference: 53.08924428411339
At round 189 accuracy: 0.705719557195572
At round 189 training accuracy: 0.7408333333333333
At round 189 training loss: 0.7346867103828117
gradient difference: 50.21019046198566
At round 190 accuracy: 0.705719557195572
At round 190 training accuracy: 0.7391666666666666
At round 190 training loss: 0.7303181148786098
gradient difference: 49.16698022011773
At round 191 accuracy: 0.7084870848708487
At round 191 training accuracy: 0.7327083333333333
At round 191 training loss: 0.7648592861493428
gradient difference: 52.829131567563444
At round 192 accuracy: 0.6918819188191881
At round 192 training accuracy: 0.7245833333333334
At round 192 training loss: 0.776995655161639
gradient difference: 54.21889948245377
At round 193 accuracy: 0.7011070110701108
At round 193 training accuracy: 0.7107291666666666
At round 193 training loss: 0.8117449983023107
gradient difference: 57.53749208250409
At round 194 accuracy: 0.6540590405904059
At round 194 training accuracy: 0.6739583333333333
At round 194 training loss: 0.9155432359920814
gradient difference: 63.641332621479826
At round 195 accuracy: 0.7001845018450185
At round 195 training accuracy: 0.7084375
At round 195 training loss: 0.8318136361024032
gradient difference: 59.054866009057285
At round 196 accuracy: 0.6900369003690037
At round 196 training accuracy: 0.7173958333333333
At round 196 training loss: 0.8176509057823569
gradient difference: 56.609979634740306
At round 197 accuracy: 0.6697416974169742
At round 197 training accuracy: 0.6889583333333333
At round 197 training loss: 0.867522753595064
gradient difference: 61.10942383983509
At round 198 accuracy: 0.6494464944649446
At round 198 training accuracy: 0.6704166666666667
At round 198 training loss: 0.9027236765421306
gradient difference: 63.142149373753384
At round 199 accuracy: 0.7066420664206642
At round 199 training accuracy: 0.7283333333333334
At round 199 training loss: 0.7958948522650947
gradient difference: 57.407816075333486
At round 200 accuracy: 0.6955719557195572
At round 200 training accuracy: 0.7061458333333334
