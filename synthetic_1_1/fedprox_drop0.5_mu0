Arguments:
	       batch_size : 10
	clients_per_round : 10
	          dataset : synthetic_1_1
	     drop_percent : 0.5
	       eval_every : 1
	    learning_rate : 0.01
	            model : mclr
	     model_params : (10,)
	               mu : 0.0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedprox
	             seed : 0
Using Federated prox to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/5.44k flops)
  dense/kernel/Regularizer/l2_regularizer (1/1.80k flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (1.80k/1.80k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  PGD/update_dense/kernel/AssignSub (600/600 flops)
  PGD/update_dense/kernel/mul (600/600 flops)
  PGD/update_dense/kernel/mul_1 (600/600 flops)
  PGD/update_dense/kernel/sub (600/600 flops)
  PGD/update_dense/bias/AssignSub (10/10 flops)
  PGD/update_dense/bias/mul (10/10 flops)
  PGD/update_dense/bias/mul_1 (10/10 flops)
  PGD/update_dense/bias/sub (10/10 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
30 Clients in Total
Training with 10 workers ---
At round 0 accuracy: 0.3016605166051661
At round 0 training accuracy: 0.28739583333333335
At round 0 training loss: 2.814805432880918
gradient difference: 116.13141207625425
At round 1 accuracy: 0.36808118081180813
At round 1 training accuracy: 0.34791666666666665
At round 1 training loss: 3.2097862391049663
gradient difference: 112.83271029923527
At round 2 accuracy: 0.36808118081180813
At round 2 training accuracy: 0.34875
At round 2 training loss: 3.563377551274995
gradient difference: 112.20009203119021
At round 3 accuracy: 0.35424354243542433
At round 3 training accuracy: 0.35020833333333334
At round 3 training loss: 2.9418862874309224
gradient difference: 109.2446921979746
At round 4 accuracy: 0.5083025830258303
At round 4 training accuracy: 0.536875
At round 4 training loss: 1.682774299659456
gradient difference: 87.87109061083078
At round 5 accuracy: 0.4981549815498155
At round 5 training accuracy: 0.4870833333333333
At round 5 training loss: 2.1242500608973205
gradient difference: 106.26882940474391
At round 6 accuracy: 0.5313653136531366
At round 6 training accuracy: 0.5563541666666667
At round 6 training loss: 1.8740574282811333
gradient difference: 96.39015898687894
At round 7 accuracy: 0.507380073800738
At round 7 training accuracy: 0.49583333333333335
At round 7 training loss: 1.6590839283230403
gradient difference: 101.66473036100533
At round 8 accuracy: 0.3533210332103321
At round 8 training accuracy: 0.36666666666666664
At round 8 training loss: 1.6908041439577937
gradient difference: 112.45128590369842
At round 9 accuracy: 0.5535055350553506
At round 9 training accuracy: 0.5753125
At round 9 training loss: 1.6763319694374998
gradient difference: 99.46204990772677
At round 10 accuracy: 0.5618081180811808
At round 10 training accuracy: 0.5666666666666667
At round 10 training loss: 1.472724422843506
gradient difference: 97.89393673399537
At round 11 accuracy: 0.5931734317343174
At round 11 training accuracy: 0.5961458333333334
At round 11 training loss: 1.4002083506373069
gradient difference: 95.6652786394031
At round 12 accuracy: 0.5784132841328413
At round 12 training accuracy: 0.6109375
At round 12 training loss: 1.4914236965744445
gradient difference: 96.7966758582477
At round 13 accuracy: 0.5276752767527675
At round 13 training accuracy: 0.5567708333333333
At round 13 training loss: 1.7748900040859978
gradient difference: 108.89254107624087
At round 14 accuracy: 0.5479704797047971
At round 14 training accuracy: 0.5747916666666667
At round 14 training loss: 1.8818524130589018
gradient difference: 110.934118631343
At round 15 accuracy: 0.5691881918819188
At round 15 training accuracy: 0.605625
At round 15 training loss: 1.8596853140369058
gradient difference: 110.06034086749584
At round 16 accuracy: 0.470479704797048
At round 16 training accuracy: 0.494375
At round 16 training loss: 2.0892743658150237
gradient difference: 123.32377908994637
At round 17 accuracy: 0.4483394833948339
At round 17 training accuracy: 0.4713541666666667
At round 17 training loss: 2.0913443886178236
gradient difference: 125.4887239778785
At round 18 accuracy: 0.45295202952029523
At round 18 training accuracy: 0.4813541666666667
At round 18 training loss: 1.874628026013573
gradient difference: 119.2569491960987
At round 19 accuracy: 0.4317343173431734
At round 19 training accuracy: 0.4607291666666667
At round 19 training loss: 1.9194062931571776
gradient difference: 121.47719842967793
At round 20 accuracy: 0.4483394833948339
At round 20 training accuracy: 0.4786458333333333
At round 20 training loss: 1.7452565786630536
gradient difference: 117.52688295255817
At round 21 accuracy: 0.5055350553505535
At round 21 training accuracy: 0.5254166666666666
At round 21 training loss: 1.566139597670796
gradient difference: 108.132904955889
At round 22 accuracy: 0.4584870848708487
At round 22 training accuracy: 0.4869791666666667
At round 22 training loss: 1.8184773331709827
gradient difference: 116.38438691035189
At round 23 accuracy: 0.5645756457564576
At round 23 training accuracy: 0.5945833333333334
At round 23 training loss: 1.4917137995952119
gradient difference: 105.82546620679861
At round 24 accuracy: 0.5461254612546126
At round 24 training accuracy: 0.568125
At round 24 training loss: 1.6101361150015145
gradient difference: 111.3859827747646
At round 25 accuracy: 0.5950184501845018
At round 25 training accuracy: 0.6302083333333334
At round 25 training loss: 1.4156606805634995
gradient difference: 103.84633250239288
At round 26 accuracy: 0.584870848708487
At round 26 training accuracy: 0.6310416666666666
At round 26 training loss: 1.3606638378215332
gradient difference: 101.01202534292462
At round 27 accuracy: 0.5968634686346863
At round 27 training accuracy: 0.62125
At round 27 training loss: 1.3569955560720215
gradient difference: 103.68527654722872
At round 28 accuracy: 0.5747232472324724
At round 28 training accuracy: 0.5784375
At round 28 training loss: 1.5457190651229273
gradient difference: 112.8277848324536
At round 29 accuracy: 0.5627306273062731
At round 29 training accuracy: 0.5552083333333333
At round 29 training loss: 1.5603678322241952
gradient difference: 115.75110744742851
At round 30 accuracy: 0.5839483394833949
At round 30 training accuracy: 0.5860416666666667
At round 30 training loss: 1.4503797490056605
gradient difference: 109.2050798210434
At round 31 accuracy: 0.5876383763837638
At round 31 training accuracy: 0.6082291666666667
At round 31 training loss: 1.503460039673373
gradient difference: 109.23687687345124
At round 32 accuracy: 0.5867158671586716
At round 32 training accuracy: 0.6222916666666667
At round 32 training loss: 1.5463331026149292
gradient difference: 108.23551240294977
At round 33 accuracy: 0.5857933579335793
At round 33 training accuracy: 0.6180208333333334
At round 33 training loss: 1.593636738859738
gradient difference: 110.43112994179313
At round 34 accuracy: 0.5904059040590406
At round 34 training accuracy: 0.6164583333333333
At round 34 training loss: 1.617636028882116
gradient difference: 111.43297194391423
At round 35 accuracy: 0.5857933579335793
At round 35 training accuracy: 0.616875
At round 35 training loss: 1.6613973678834737
gradient difference: 112.17948271165749
At round 36 accuracy: 0.5359778597785978
At round 36 training accuracy: 0.5311458333333333
At round 36 training loss: 1.760911974000434
gradient difference: 124.32577738091624
At round 37 accuracy: 0.5793357933579336
At round 37 training accuracy: 0.6128125
At round 37 training loss: 1.6188455163082107
gradient difference: 111.38637749327367
At round 38 accuracy: 0.4935424354243542
At round 38 training accuracy: 0.480625
At round 38 training loss: 2.054046669853851
gradient difference: 139.32568689827968
At round 39 accuracy: 0.4621771217712177
At round 39 training accuracy: 0.46166666666666667
At round 39 training loss: 2.226676251521955
gradient difference: 145.55967424881126
At round 40 accuracy: 0.6060885608856088
At round 40 training accuracy: 0.6434375
At round 40 training loss: 1.5313530469421919
gradient difference: 105.97467719670885
At round 41 accuracy: 0.6051660516605166
At round 41 training accuracy: 0.6396875
At round 41 training loss: 1.5731113561801613
gradient difference: 107.87241637165864
At round 42 accuracy: 0.5894833948339483
At round 42 training accuracy: 0.6257291666666667
At round 42 training loss: 1.5992765664324786
gradient difference: 108.7407150991681
At round 43 accuracy: 0.6023985239852399
At round 43 training accuracy: 0.6335416666666667
At round 43 training loss: 1.602025061758856
gradient difference: 108.72459491947446
At round 44 accuracy: 0.6042435424354243
At round 44 training accuracy: 0.6222916666666667
At round 44 training loss: 1.5416554184723645
gradient difference: 109.97969301042566
At round 45 accuracy: 0.45387453874538747
At round 45 training accuracy: 0.4796875
At round 45 training loss: 2.232055993319179
gradient difference: 131.4313415337028
At round 46 accuracy: 0.470479704797048
At round 46 training accuracy: 0.4948958333333333
At round 46 training loss: 2.054291767796191
gradient difference: 127.15529504219532
At round 47 accuracy: 0.4732472324723247
At round 47 training accuracy: 0.4898958333333333
At round 47 training loss: 2.1088318286758536
gradient difference: 129.0226900735831
At round 48 accuracy: 0.6199261992619927
At round 48 training accuracy: 0.6333333333333333
At round 48 training loss: 1.4170311901842554
gradient difference: 106.32096405388954
At round 49 accuracy: 0.6263837638376384
At round 49 training accuracy: 0.6542708333333334
At round 49 training loss: 1.4245605364224563
gradient difference: 103.91243549878422
At round 50 accuracy: 0.5977859778597786
At round 50 training accuracy: 0.5840625
At round 50 training loss: 1.6070165334952373
gradient difference: 117.48446961873518
At round 51 accuracy: 0.525830258302583
At round 51 training accuracy: 0.5166666666666667
At round 51 training loss: 1.8394270005604874
gradient difference: 129.877360633901
At round 52 accuracy: 0.5996309963099631
At round 52 training accuracy: 0.6165625
At round 52 training loss: 1.5361423175781965
gradient difference: 106.74382141447644
At round 53 accuracy: 0.6199261992619927
At round 53 training accuracy: 0.6472916666666667
At round 53 training loss: 1.4870862432724485
gradient difference: 105.88420920140256
At round 54 accuracy: 0.6070110701107011
At round 54 training accuracy: 0.6407291666666667
At round 54 training loss: 1.5178579113911836
gradient difference: 105.65580977285818
At round 55 accuracy: 0.5922509225092251
At round 55 training accuracy: 0.6091666666666666
At round 55 training loss: 1.5457225391175597
gradient difference: 106.80654884684509
At round 56 accuracy: 0.6245387453874539
At round 56 training accuracy: 0.6582291666666666
At round 56 training loss: 1.3946074335090817
gradient difference: 99.28681053082214
At round 57 accuracy: 0.6291512915129152
At round 57 training accuracy: 0.6603125
At round 57 training loss: 1.3585937547466407
gradient difference: 97.50881092164255
At round 58 accuracy: 0.6356088560885609
At round 58 training accuracy: 0.6609375
At round 58 training loss: 1.3388357266504318
gradient difference: 96.52462040164532
At round 59 accuracy: 0.566420664206642
At round 59 training accuracy: 0.589375
At round 59 training loss: 1.5519354875711724
gradient difference: 106.04742512664878
At round 60 accuracy: 0.5885608856088561
At round 60 training accuracy: 0.6072916666666667
At round 60 training loss: 1.4438978233886883
gradient difference: 100.29926396293045
At round 61 accuracy: 0.6429889298892989
At round 61 training accuracy: 0.6615625
At round 61 training loss: 1.2860770634639387
gradient difference: 93.65680580492965
At round 62 accuracy: 0.6365313653136532
At round 62 training accuracy: 0.6634375
At round 62 training loss: 1.2485026961394274
gradient difference: 89.16172349294798
At round 63 accuracy: 0.6439114391143912
At round 63 training accuracy: 0.6690625
At round 63 training loss: 1.2106960265726472
gradient difference: 88.00369762294926
At round 64 accuracy: 0.6402214022140221
At round 64 training accuracy: 0.6646875
At round 64 training loss: 1.216731674754992
gradient difference: 89.55309883397504
At round 65 accuracy: 0.6420664206642066
At round 65 training accuracy: 0.65375
At round 65 training loss: 1.2758167057686174
gradient difference: 94.10240940901187
At round 66 accuracy: 0.6254612546125461
At round 66 training accuracy: 0.6283333333333333
At round 66 training loss: 1.2838935025548563
gradient difference: 96.01881084628116
At round 67 accuracy: 0.6365313653136532
At round 67 training accuracy: 0.6635416666666667
At round 67 training loss: 1.1944434455658
gradient difference: 89.83470668690664
At round 68 accuracy: 0.6236162361623616
At round 68 training accuracy: 0.6501041666666667
At round 68 training loss: 1.157125513784898
gradient difference: 87.04032022886283
At round 69 accuracy: 0.6217712177121771
At round 69 training accuracy: 0.6519791666666667
At round 69 training loss: 1.1346617782100414
gradient difference: 85.16629026794077
At round 70 accuracy: 0.6328413284132841
At round 70 training accuracy: 0.6503125
At round 70 training loss: 1.1937006099413459
gradient difference: 90.79908107519448
At round 71 accuracy: 0.6291512915129152
At round 71 training accuracy: 0.6664583333333334
At round 71 training loss: 1.200909108800503
gradient difference: 89.50427855208234
At round 72 accuracy: 0.6319188191881919
At round 72 training accuracy: 0.6635416666666667
At round 72 training loss: 1.226657238585564
gradient difference: 91.03640635556191
At round 73 accuracy: 0.6245387453874539
At round 73 training accuracy: 0.64125
At round 73 training loss: 1.2376746291387826
gradient difference: 93.91140419548667
At round 74 accuracy: 0.6088560885608856
At round 74 training accuracy: 0.5907291666666666
At round 74 training loss: 1.3483292155852542
gradient difference: 101.8573203109911
At round 75 accuracy: 0.6125461254612546
At round 75 training accuracy: 0.6265625
At round 75 training loss: 1.176565532522897
gradient difference: 87.04447901924759
At round 76 accuracy: 0.6374538745387454
At round 76 training accuracy: 0.6636458333333334
At round 76 training loss: 1.1331438954469437
gradient difference: 85.14381592220471
At round 77 accuracy: 0.5987084870848709
At round 77 training accuracy: 0.6173958333333334
At round 77 training loss: 1.2079879116639496
gradient difference: 88.53069062910353
At round 78 accuracy: 0.6476014760147601
At round 78 training accuracy: 0.665625
At round 78 training loss: 1.1432268426241352
gradient difference: 86.0984750270298
At round 79 accuracy: 0.6448339483394834
At round 79 training accuracy: 0.6648958333333334
At round 79 training loss: 1.1716847026968995
gradient difference: 87.31601891151382
At round 80 accuracy: 0.6374538745387454
At round 80 training accuracy: 0.6533333333333333
At round 80 training loss: 1.171052150420534
gradient difference: 88.99562955114372
At round 81 accuracy: 0.525830258302583
At round 81 training accuracy: 0.5470833333333334
At round 81 training loss: 1.487864454621449
gradient difference: 101.63642301023997
At round 82 accuracy: 0.6476014760147601
At round 82 training accuracy: 0.6627083333333333
At round 82 training loss: 1.1360997924099987
gradient difference: 87.19702393448833
At round 83 accuracy: 0.6476014760147601
At round 83 training accuracy: 0.67125
At round 83 training loss: 1.1227675631518166
gradient difference: 84.1399694610147
At round 84 accuracy: 0.6466789667896679
At round 84 training accuracy: 0.664375
At round 84 training loss: 1.1530347261562321
gradient difference: 87.2150360190586
At round 85 accuracy: 0.6162361623616236
At round 85 training accuracy: 0.6308333333333334
At round 85 training loss: 1.2274136918907363
gradient difference: 88.9235688473275
At round 86 accuracy: 0.6245387453874539
At round 86 training accuracy: 0.6414583333333334
At round 86 training loss: 1.1946281605322535
gradient difference: 82.97812032204985
At round 87 accuracy: 0.6226937269372693
At round 87 training accuracy: 0.6403125
At round 87 training loss: 1.180350418422992
gradient difference: 82.18544248875692
At round 88 accuracy: 0.5452029520295203
At round 88 training accuracy: 0.569375
At round 88 training loss: 1.3691608867701144
gradient difference: 93.87053755015985
At round 89 accuracy: 0.5571955719557196
At round 89 training accuracy: 0.583125
At round 89 training loss: 1.30510699664553
gradient difference: 91.14684842351149
At round 90 accuracy: 0.5802583025830258
At round 90 training accuracy: 0.5936458333333333
At round 90 training loss: 1.229425383862108
gradient difference: 89.21028237747491
At round 91 accuracy: 0.5756457564575646
At round 91 training accuracy: 0.5875
At round 91 training loss: 1.2128985247202217
gradient difference: 86.43286213148407
At round 92 accuracy: 0.6595940959409594
At round 92 training accuracy: 0.6886458333333333
At round 92 training loss: 0.9775030402621875
gradient difference: 73.91164595381738
At round 93 accuracy: 0.6337638376383764
At round 93 training accuracy: 0.63125
At round 93 training loss: 1.078498255405575
gradient difference: 84.02469438004182
At round 94 accuracy: 0.6595940959409594
At round 94 training accuracy: 0.6640625
At round 94 training loss: 0.9854786197437594
gradient difference: 73.2079850251529
At round 95 accuracy: 0.6586715867158671
At round 95 training accuracy: 0.6608333333333334
At round 95 training loss: 0.9737359473264465
gradient difference: 71.8593632197696
At round 96 accuracy: 0.6328413284132841
At round 96 training accuracy: 0.6204166666666666
At round 96 training loss: 1.0751342613312105
gradient difference: 78.92716959012137
At round 97 accuracy: 0.6494464944649446
At round 97 training accuracy: 0.6528125
At round 97 training loss: 0.9834769604324053
gradient difference: 73.62757690910199
At round 98 accuracy: 0.6660516605166051
At round 98 training accuracy: 0.69375
At round 98 training loss: 0.9401186825986951
gradient difference: 71.2877652373586
At round 99 accuracy: 0.6595940959409594
At round 99 training accuracy: 0.6772916666666666
At round 99 training loss: 0.9998845436889678
gradient difference: 76.45784386915011
At round 100 accuracy: 0.6512915129151291
At round 100 training accuracy: 0.6582291666666666
At round 100 training loss: 1.0487580868198225
gradient difference: 80.37141992214467
At round 101 accuracy: 0.6337638376383764
At round 101 training accuracy: 0.6242708333333333
At round 101 training loss: 1.1214169426231335
gradient difference: 86.52209396200034
At round 102 accuracy: 0.6199261992619927
At round 102 training accuracy: 0.601875
At round 102 training loss: 1.1806003601197153
gradient difference: 89.39018580285058
At round 103 accuracy: 0.6595940959409594
At round 103 training accuracy: 0.67375
At round 103 training loss: 0.9788264661499609
gradient difference: 76.77061294237936
At round 104 accuracy: 0.6678966789667896
At round 104 training accuracy: 0.6870833333333334
At round 104 training loss: 0.9911610653810203
gradient difference: 76.69858029022394
At round 105 accuracy: 0.6540590405904059
At round 105 training accuracy: 0.6630208333333333
At round 105 training loss: 1.0650906849807749
gradient difference: 82.15545336897684
At round 106 accuracy: 0.6282287822878229
At round 106 training accuracy: 0.61875
At round 106 training loss: 1.15029757223092
gradient difference: 89.14168979058522
At round 107 accuracy: 0.6420664206642066
At round 107 training accuracy: 0.6553125
At round 107 training loss: 1.088332171368723
gradient difference: 84.50340248487798
At round 108 accuracy: 0.6494464944649446
At round 108 training accuracy: 0.6813541666666667
At round 108 training loss: 1.012616727690523
gradient difference: 80.01953765952018
At round 109 accuracy: 0.6402214022140221
At round 109 training accuracy: 0.6760416666666667
At round 109 training loss: 1.0519984516858434
gradient difference: 80.27836803637653
At round 110 accuracy: 0.6559040590405905
At round 110 training accuracy: 0.6864583333333333
At round 110 training loss: 1.0183456718968227
gradient difference: 78.55065891304204
At round 111 accuracy: 0.6236162361623616
At round 111 training accuracy: 0.6072916666666667
At round 111 training loss: 1.180876955864951
gradient difference: 89.7550346657717
At round 112 accuracy: 0.6568265682656826
At round 112 training accuracy: 0.6646875
At round 112 training loss: 1.03919281778081
gradient difference: 80.38363056308334
At round 113 accuracy: 0.6688191881918819
At round 113 training accuracy: 0.6766666666666666
At round 113 training loss: 1.0204309129156173
gradient difference: 79.59435857948338
At round 114 accuracy: 0.6531365313653137
At round 114 training accuracy: 0.6627083333333333
At round 114 training loss: 1.037882181107998
gradient difference: 77.63028632940555
At round 115 accuracy: 0.665129151291513
At round 115 training accuracy: 0.688125
At round 115 training loss: 1.0073210455306496
gradient difference: 76.04728783387587
At round 116 accuracy: 0.6605166051660517
At round 116 training accuracy: 0.6916666666666667
At round 116 training loss: 0.992080006209823
gradient difference: 77.07055135865335
At round 117 accuracy: 0.6614391143911439
At round 117 training accuracy: 0.6879166666666666
At round 117 training loss: 1.0242922866391018
gradient difference: 79.72274969242368
At round 118 accuracy: 0.6309963099630996
At round 118 training accuracy: 0.6241666666666666
At round 118 training loss: 1.1391568198303381
gradient difference: 87.38136416828256
At round 119 accuracy: 0.6236162361623616
At round 119 training accuracy: 0.6117708333333334
At round 119 training loss: 1.1773859624254206
gradient difference: 89.17625947559503
At round 120 accuracy: 0.6448339483394834
At round 120 training accuracy: 0.6591666666666667
At round 120 training loss: 1.0408984162068615
gradient difference: 80.55148114176644
At round 121 accuracy: 0.6328413284132841
At round 121 training accuracy: 0.6241666666666666
At round 121 training loss: 1.124998502690966
gradient difference: 87.58785945342734
At round 122 accuracy: 0.5894833948339483
At round 122 training accuracy: 0.5814583333333333
At round 122 training loss: 1.2982251039566473
gradient difference: 97.75108117902913
At round 123 accuracy: 0.6595940959409594
At round 123 training accuracy: 0.6936458333333333
At round 123 training loss: 0.948661036567452
gradient difference: 74.83507233365772
At round 124 accuracy: 0.6411439114391144
At round 124 training accuracy: 0.6546875
At round 124 training loss: 1.0199407814474155
gradient difference: 79.6018452484307
At round 125 accuracy: 0.6392988929889298
At round 125 training accuracy: 0.6546875
At round 125 training loss: 1.0120750479617466
gradient difference: 79.49394099011728
At round 126 accuracy: 0.5756457564575646
At round 126 training accuracy: 0.595625
At round 126 training loss: 1.1427442369423806
gradient difference: 87.24247021629786
At round 127 accuracy: 0.533210332103321
At round 127 training accuracy: 0.5638541666666667
At round 127 training loss: 1.322964608396093
gradient difference: 94.38234714702953
At round 128 accuracy: 0.503690036900369
At round 128 training accuracy: 0.5294791666666666
At round 128 training loss: 1.697958782701753
gradient difference: 104.33546061887043
At round 129 accuracy: 0.496309963099631
At round 129 training accuracy: 0.5202083333333334
At round 129 training loss: 2.1461639735645925
gradient difference: 107.74942534668361
At round 130 accuracy: 0.6402214022140221
At round 130 training accuracy: 0.6661458333333333
At round 130 training loss: 0.9449894544156269
gradient difference: 74.76204987755787
At round 131 accuracy: 0.6494464944649446
At round 131 training accuracy: 0.6846875
At round 131 training loss: 0.9085535829141737
gradient difference: 72.2907636931838
At round 132 accuracy: 0.6586715867158671
At round 132 training accuracy: 0.6895833333333333
At round 132 training loss: 0.9316248143914466
gradient difference: 73.70099655387612
At round 133 accuracy: 0.6429889298892989
At round 133 training accuracy: 0.6535416666666667
At round 133 training loss: 0.990427371400098
gradient difference: 78.42255282147971
At round 134 accuracy: 0.6531365313653137
At round 134 training accuracy: 0.6786458333333333
At round 134 training loss: 0.9392721633830419
gradient difference: 73.72744761796103
At round 135 accuracy: 0.6623616236162362
At round 135 training accuracy: 0.699375
At round 135 training loss: 0.8950825211638584
gradient difference: 69.71874251837205
At round 136 accuracy: 0.6420664206642066
At round 136 training accuracy: 0.6473958333333333
At round 136 training loss: 1.0171768210098768
gradient difference: 78.79770915286282
At round 137 accuracy: 0.6678966789667896
At round 137 training accuracy: 0.695
At round 137 training loss: 0.9077792858099565
gradient difference: 69.69243878126296
At round 138 accuracy: 0.672509225092251
At round 138 training accuracy: 0.691875
At round 138 training loss: 0.9137746572572117
gradient difference: 69.96092954969255
At round 139 accuracy: 0.6669741697416974
At round 139 training accuracy: 0.6939583333333333
At round 139 training loss: 0.9311761816497892
gradient difference: 71.07740721491217
At round 140 accuracy: 0.6688191881918819
At round 140 training accuracy: 0.681875
At round 140 training loss: 0.9453351170538614
gradient difference: 71.3378033005582
At round 141 accuracy: 0.6605166051660517
At round 141 training accuracy: 0.6894791666666666
At round 141 training loss: 0.8957150909490883
gradient difference: 66.69272968253405
At round 142 accuracy: 0.6706642066420664
At round 142 training accuracy: 0.7042708333333333
At round 142 training loss: 0.8731033448983605
gradient difference: 65.24992594787014
At round 143 accuracy: 0.6097785977859779
At round 143 training accuracy: 0.6205208333333333
At round 143 training loss: 1.0596849006243672
gradient difference: 76.33401993243515
At round 144 accuracy: 0.6660516605166051
At round 144 training accuracy: 0.6940625
At round 144 training loss: 0.857246316166905
gradient difference: 64.27272627123894
At round 145 accuracy: 0.6697416974169742
At round 145 training accuracy: 0.7032291666666667
At round 145 training loss: 0.8550119195490454
gradient difference: 64.4087566150875
At round 146 accuracy: 0.6761992619926199
At round 146 training accuracy: 0.7111458333333334
At round 146 training loss: 0.8344201112988715
gradient difference: 60.6376726296448
At round 147 accuracy: 0.6955719557195572
At round 147 training accuracy: 0.7257291666666666
At round 147 training loss: 0.8105744701484219
gradient difference: 59.546268416653966
At round 148 accuracy: 0.6291512915129152
At round 148 training accuracy: 0.6570833333333334
At round 148 training loss: 0.9405463782139123
gradient difference: 69.2104445882994
At round 149 accuracy: 0.6808118081180812
At round 149 training accuracy: 0.7117708333333334
At round 149 training loss: 0.8370135655098905
gradient difference: 62.68005899901282
At round 150 accuracy: 0.6881918819188192
At round 150 training accuracy: 0.7216666666666667
At round 150 training loss: 0.8179415981626759
gradient difference: 60.68472348324251
At round 151 accuracy: 0.6845018450184502
At round 151 training accuracy: 0.7171875
At round 151 training loss: 0.8286364947197338
gradient difference: 61.42724849857253
At round 152 accuracy: 0.6678966789667896
At round 152 training accuracy: 0.688125
At round 152 training loss: 0.9134004483340928
gradient difference: 66.9659017290428
At round 153 accuracy: 0.6808118081180812
At round 153 training accuracy: 0.7123958333333333
At round 153 training loss: 0.8905178261299928
gradient difference: 66.02359613450504
At round 154 accuracy: 0.6789667896678967
At round 154 training accuracy: 0.7020833333333333
At round 154 training loss: 0.9248694985794524
gradient difference: 69.434384372918
At round 155 accuracy: 0.6863468634686347
At round 155 training accuracy: 0.713125
At round 155 training loss: 0.8895826272976896
gradient difference: 66.42783340696867
At round 156 accuracy: 0.6697416974169742
At round 156 training accuracy: 0.7028125
At round 156 training loss: 0.9177721531518425
gradient difference: 68.16719662713494
At round 157 accuracy: 0.5553505535055351
At round 157 training accuracy: 0.5826041666666667
At round 157 training loss: 1.349811436055849
gradient difference: 87.86210267126049
At round 158 accuracy: 0.6734317343173432
At round 158 training accuracy: 0.6897916666666667
At round 158 training loss: 0.9285114656730244
gradient difference: 68.56721304232933
At round 159 accuracy: 0.6697416974169742
At round 159 training accuracy: 0.6720833333333334
At round 159 training loss: 0.9728054638191437
gradient difference: 73.83444078815629
At round 160 accuracy: 0.6752767527675276
At round 160 training accuracy: 0.6884375
At round 160 training loss: 0.9082347969726349
gradient difference: 70.18251972712231
At round 161 accuracy: 0.6660516605166051
At round 161 training accuracy: 0.6578125
At round 161 training loss: 0.9644429204830279
gradient difference: 73.16907906324764
At round 162 accuracy: 0.6273062730627307
At round 162 training accuracy: 0.6114583333333333
At round 162 training loss: 1.117418522099033
gradient difference: 80.2872973432742
At round 163 accuracy: 0.6817343173431735
At round 163 training accuracy: 0.7115625
At round 163 training loss: 0.8640984517910207
gradient difference: 62.62854043601273
At round 164 accuracy: 0.6734317343173432
At round 164 training accuracy: 0.7026041666666667
At round 164 training loss: 0.8685289061395451
gradient difference: 62.0777076108077
At round 165 accuracy: 0.6946494464944649
At round 165 training accuracy: 0.7242708333333333
At round 165 training loss: 0.8465073314526429
gradient difference: 61.14346565938733
At round 166 accuracy: 0.6153136531365314
At round 166 training accuracy: 0.6316666666666667
At round 166 training loss: 1.0596103209645178
gradient difference: 74.29721799489529
At round 167 accuracy: 0.5765682656826568
At round 167 training accuracy: 0.5984375
At round 167 training loss: 1.209239260717295
gradient difference: 80.39413741420117
At round 168 accuracy: 0.6964944649446494
At round 168 training accuracy: 0.7190625
At round 168 training loss: 0.8400442885747179
gradient difference: 61.231869589826914
At round 169 accuracy: 0.6946494464944649
At round 169 training accuracy: 0.7214583333333333
At round 169 training loss: 0.8324902830009038
gradient difference: 59.24392508836936
At round 170 accuracy: 0.690959409594096
At round 170 training accuracy: 0.7221875
At round 170 training loss: 0.8318239631131291
gradient difference: 59.99224808643702
At round 171 accuracy: 0.5498154981549815
At round 171 training accuracy: 0.571875
At round 171 training loss: 1.3822915965101372
gradient difference: 85.97514968610544
At round 172 accuracy: 0.544280442804428
At round 172 training accuracy: 0.5680208333333333
At round 172 training loss: 1.3922376363926257
gradient difference: 86.41263709847405
At round 173 accuracy: 0.5470479704797048
At round 173 training accuracy: 0.5721875
At round 173 training loss: 1.323316484942722
gradient difference: 84.76052170707104
At round 174 accuracy: 0.5433579335793358
At round 174 training accuracy: 0.5675
At round 174 training loss: 1.3773183136697238
gradient difference: 86.30808990964805
At round 175 accuracy: 0.5212177121771218
At round 175 training accuracy: 0.5453125
At round 175 training loss: 1.9695967244838053
gradient difference: 96.57029894384775
At round 176 accuracy: 0.6891143911439115
At round 176 training accuracy: 0.7115625
At round 176 training loss: 0.8153318461263552
gradient difference: 60.46313759927577
At round 177 accuracy: 0.6918819188191881
At round 177 training accuracy: 0.728125
At round 177 training loss: 0.7771780473878607
gradient difference: 54.57995186652333
At round 178 accuracy: 0.6798892988929889
At round 178 training accuracy: 0.7222916666666667
At round 178 training loss: 0.7779709348113587
gradient difference: 54.70764148361563
At round 179 accuracy: 0.6466789667896679
At round 179 training accuracy: 0.6721875
At round 179 training loss: 0.8710992975501964
gradient difference: 60.800817598633444
At round 180 accuracy: 0.551660516605166
At round 180 training accuracy: 0.5736458333333333
At round 180 training loss: 1.3887208532495423
gradient difference: 82.49987259635148
At round 181 accuracy: 0.6512915129151291
At round 181 training accuracy: 0.6748958333333334
At round 181 training loss: 0.8561645821621642
gradient difference: 58.61633490882714
At round 182 accuracy: 0.6466789667896679
At round 182 training accuracy: 0.6728125
At round 182 training loss: 0.8640019034516687
gradient difference: 59.219904221269886
At round 183 accuracy: 0.6974169741697417
At round 183 training accuracy: 0.7271875
At round 183 training loss: 0.7842445257383709
gradient difference: 55.24620848930215
At round 184 accuracy: 0.6928044280442804
At round 184 training accuracy: 0.70625
At round 184 training loss: 0.8124934418313206
gradient difference: 57.72313000084817
At round 185 accuracy: 0.6761992619926199
At round 185 training accuracy: 0.6845833333333333
At round 185 training loss: 0.8553844655118883
gradient difference: 60.450703986694165
At round 186 accuracy: 0.7001845018450185
At round 186 training accuracy: 0.7232291666666667
At round 186 training loss: 0.7833354354696348
gradient difference: 54.18339998572944
At round 187 accuracy: 0.6798892988929889
At round 187 training accuracy: 0.7122916666666667
At round 187 training loss: 0.8313885847323884
gradient difference: 57.293569165252585
At round 188 accuracy: 0.705719557195572
At round 188 training accuracy: 0.7380208333333333
At round 188 training loss: 0.7577547148490945
gradient difference: 51.53880678934588
At round 189 accuracy: 0.7029520295202952
At round 189 training accuracy: 0.7329166666666667
At round 189 training loss: 0.7927153281060358
gradient difference: 54.93730990651887
At round 190 accuracy: 0.6974169741697417
At round 190 training accuracy: 0.7280208333333333
At round 190 training loss: 0.7916112879524008
gradient difference: 54.18905393941518
At round 191 accuracy: 0.683579335793358
At round 191 training accuracy: 0.704375
At round 191 training loss: 0.8551668313362946
gradient difference: 58.84017240993747
At round 192 accuracy: 0.6457564575645757
At round 192 training accuracy: 0.664375
At round 192 training loss: 0.9496948575709636
gradient difference: 65.20713136300459
At round 193 accuracy: 0.7020295202952029
At round 193 training accuracy: 0.71625
At round 193 training loss: 0.8515771046839654
gradient difference: 59.74702259473041
At round 194 accuracy: 0.6992619926199262
At round 194 training accuracy: 0.72375
At round 194 training loss: 0.8559206889942288
gradient difference: 60.130996711610365
At round 195 accuracy: 0.6789667896678967
At round 195 training accuracy: 0.6866666666666666
At round 195 training loss: 0.9380263112826893
gradient difference: 64.53949665973738
At round 196 accuracy: 0.5719557195571956
At round 196 training accuracy: 0.5908333333333333
At round 196 training loss: 1.3359201231629898
gradient difference: 82.5838678130802
At round 197 accuracy: 0.5507380073800738
At round 197 training accuracy: 0.574375
At round 197 training loss: 1.4878151626403755
gradient difference: 88.0582749385701
At round 198 accuracy: 0.5304428044280443
At round 198 training accuracy: 0.5553125
At round 198 training loss: 1.8845545295160264
gradient difference: 95.26261135360711
At round 199 accuracy: 0.7011070110701108
At round 199 training accuracy: 0.7258333333333333
At round 199 training loss: 0.8350754187100877
gradient difference: 60.03103529213386
At round 200 accuracy: 0.6937269372693727
At round 200 training accuracy: 0.72625
