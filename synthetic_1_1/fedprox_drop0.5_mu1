Arguments:
	       batch_size : 10
	clients_per_round : 10
	          dataset : synthetic_1_1
	     drop_percent : 0.5
	       eval_every : 1
	    learning_rate : 0.01
	            model : mclr
	     model_params : (10,)
	               mu : 1.0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedprox
	             seed : 0
Using Federated prox to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/5.44k flops)
  dense/kernel/Regularizer/l2_regularizer (1/1.80k flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (1.80k/1.80k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  PGD/update_dense/kernel/AssignSub (600/600 flops)
  PGD/update_dense/kernel/mul (600/600 flops)
  PGD/update_dense/kernel/mul_1 (600/600 flops)
  PGD/update_dense/kernel/sub (600/600 flops)
  PGD/update_dense/bias/AssignSub (10/10 flops)
  PGD/update_dense/bias/mul (10/10 flops)
  PGD/update_dense/bias/mul_1 (10/10 flops)
  PGD/update_dense/bias/sub (10/10 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
30 Clients in Total
Training with 10 workers ---
At round 0 accuracy: 0.3016605166051661
At round 0 training accuracy: 0.28739583333333335
At round 0 training loss: 2.814805432880918
gradient difference: 116.13141207625425
At round 1 accuracy: 0.33579335793357934
At round 1 training accuracy: 0.32208333333333333
At round 1 training loss: 3.0104242281739912
gradient difference: 114.89492903909189
At round 2 accuracy: 0.3118081180811808
At round 2 training accuracy: 0.3025
At round 2 training loss: 3.235699650744597
gradient difference: 114.79141285884258
At round 3 accuracy: 0.3496309963099631
At round 3 training accuracy: 0.33260416666666665
At round 3 training loss: 2.83769722742339
gradient difference: 110.09012118445726
At round 4 accuracy: 0.38099630996309963
At round 4 training accuracy: 0.394375
At round 4 training loss: 1.6340224720165133
gradient difference: 80.93213675025274
At round 5 accuracy: 0.34870848708487084
At round 5 training accuracy: 0.32135416666666666
At round 5 training loss: 1.7002755344410738
gradient difference: 92.24103691747523
At round 6 accuracy: 0.37915129151291516
At round 6 training accuracy: 0.35791666666666666
At round 6 training loss: 1.7935165145620704
gradient difference: 104.02668014003612
At round 7 accuracy: 0.41420664206642066
At round 7 training accuracy: 0.39645833333333336
At round 7 training loss: 1.70119458305339
gradient difference: 98.41804044740066
At round 8 accuracy: 0.40313653136531363
At round 8 training accuracy: 0.39166666666666666
At round 8 training loss: 1.7098699975013734
gradient difference: 92.75645271714772
At round 9 accuracy: 0.3966789667896679
At round 9 training accuracy: 0.388125
At round 9 training loss: 1.629221767509977
gradient difference: 103.47207860260579
At round 10 accuracy: 0.40682656826568264
At round 10 training accuracy: 0.3959375
At round 10 training loss: 1.465878223006924
gradient difference: 92.68463880796094
At round 11 accuracy: 0.42712177121771217
At round 11 training accuracy: 0.420625
At round 11 training loss: 1.4266668517763417
gradient difference: 84.8686985604109
At round 12 accuracy: 0.4381918819188192
At round 12 training accuracy: 0.43427083333333333
At round 12 training loss: 1.254985729623586
gradient difference: 79.29706858806375
At round 13 accuracy: 0.4114391143911439
At round 13 training accuracy: 0.43614583333333334
At round 13 training loss: 1.340459948455294
gradient difference: 87.10575990415721
At round 14 accuracy: 0.4769372693726937
At round 14 training accuracy: 0.511875
At round 14 training loss: 1.1988164942525328
gradient difference: 73.58332259381581
At round 15 accuracy: 0.45940959409594095
At round 15 training accuracy: 0.45166666666666666
At round 15 training loss: 1.256043856324007
gradient difference: 81.57794593890087
At round 16 accuracy: 0.49169741697416974
At round 16 training accuracy: 0.48552083333333335
At round 16 training loss: 1.1784982424850265
gradient difference: 74.38828378474561
At round 17 accuracy: 0.559040590405904
At round 17 training accuracy: 0.5772916666666666
At round 17 training loss: 1.091568973530084
gradient difference: 65.47371102400437
At round 18 accuracy: 0.5230627306273062
At round 18 training accuracy: 0.5196875
At round 18 training loss: 1.1171639832730094
gradient difference: 70.44074633719397
At round 19 accuracy: 0.5913284132841329
At round 19 training accuracy: 0.6139583333333334
At round 19 training loss: 1.0450973560909431
gradient difference: 61.47433253256548
At round 20 accuracy: 0.6005535055350554
At round 20 training accuracy: 0.6209375
At round 20 training loss: 1.0467345223762095
gradient difference: 61.494507128796045
At round 21 accuracy: 0.5922509225092251
At round 21 training accuracy: 0.615625
At round 21 training loss: 1.0712999771349132
gradient difference: 62.864189398808016
At round 22 accuracy: 0.5894833948339483
At round 22 training accuracy: 0.6210416666666667
At round 22 training loss: 1.1030022876958052
gradient difference: 64.49848427251207
At round 23 accuracy: 0.5968634686346863
At round 23 training accuracy: 0.62375
At round 23 training loss: 0.9957191836771866
gradient difference: 62.59421530092042
At round 24 accuracy: 0.47878228782287824
At round 24 training accuracy: 0.5119791666666667
At round 24 training loss: 1.1062681486271322
gradient difference: 75.55491970044778
At round 25 accuracy: 0.5811808118081181
At round 25 training accuracy: 0.618125
At round 25 training loss: 0.9703847338010867
gradient difference: 62.01626169515318
At round 26 accuracy: 0.5904059040590406
At round 26 training accuracy: 0.626875
At round 26 training loss: 0.9605988640834888
gradient difference: 60.74153579074507
At round 27 accuracy: 0.6143911439114391
At round 27 training accuracy: 0.6436458333333334
At round 27 training loss: 0.962534436006099
gradient difference: 59.44382375232317
At round 28 accuracy: 0.5525830258302583
At round 28 training accuracy: 0.5546875
At round 28 training loss: 1.0040045850661894
gradient difference: 68.44103938079176
At round 29 accuracy: 0.5765682656826568
At round 29 training accuracy: 0.5755208333333334
At round 29 training loss: 0.9825836114833753
gradient difference: 66.71929577628212
At round 30 accuracy: 0.5996309963099631
At round 30 training accuracy: 0.6128125
At round 30 training loss: 0.9514448266165952
gradient difference: 63.21657359494695
At round 31 accuracy: 0.6005535055350554
At round 31 training accuracy: 0.6117708333333334
At round 31 training loss: 0.9447115641770264
gradient difference: 64.16315998752648
At round 32 accuracy: 0.6023985239852399
At round 32 training accuracy: 0.651875
At round 32 training loss: 0.9125994443024198
gradient difference: 60.673335948571555
At round 33 accuracy: 0.6171586715867159
At round 33 training accuracy: 0.653125
At round 33 training loss: 0.9120174760806063
gradient difference: 60.9902363513986
At round 34 accuracy: 0.6153136531365314
At round 34 training accuracy: 0.6509375
At round 34 training loss: 0.9105577147131165
gradient difference: 61.52439612420422
At round 35 accuracy: 0.6005535055350554
At round 35 training accuracy: 0.6473958333333333
At round 35 training loss: 0.9125207919689516
gradient difference: 62.03168623472062
At round 36 accuracy: 0.6107011070110702
At round 36 training accuracy: 0.6561458333333333
At round 36 training loss: 0.8907764454868933
gradient difference: 60.74239070633276
At round 37 accuracy: 0.5285977859778598
At round 37 training accuracy: 0.5395833333333333
At round 37 training loss: 1.0180469277873636
gradient difference: 75.09269256984904
At round 38 accuracy: 0.5193726937269373
At round 38 training accuracy: 0.5276041666666667
At round 38 training loss: 1.0429944355289142
gradient difference: 77.5512326294223
At round 39 accuracy: 0.5285977859778598
At round 39 training accuracy: 0.5327083333333333
At round 39 training loss: 1.0339777492855986
gradient difference: 76.55287186511542
At round 40 accuracy: 0.5433579335793358
At round 40 training accuracy: 0.5867708333333334
At round 40 training loss: 0.9500028962207338
gradient difference: 68.07281679431992
At round 41 accuracy: 0.5654981549815498
At round 41 training accuracy: 0.6086458333333333
At round 41 training loss: 0.9176965244673192
gradient difference: 64.97276957804505
At round 42 accuracy: 0.5802583025830258
At round 42 training accuracy: 0.6198958333333333
At round 42 training loss: 0.8995620674950381
gradient difference: 63.36049847088887
At round 43 accuracy: 0.6005535055350554
At round 43 training accuracy: 0.643125
At round 43 training loss: 0.8817989436226586
gradient difference: 61.63740312900752
At round 44 accuracy: 0.6143911439114391
At round 44 training accuracy: 0.6630208333333333
At round 44 training loss: 0.8625823587924242
gradient difference: 59.43023097544928
At round 45 accuracy: 0.5857933579335793
At round 45 training accuracy: 0.6220833333333333
At round 45 training loss: 0.8974870747700333
gradient difference: 62.630053795902974
At round 46 accuracy: 0.5987084870848709
At round 46 training accuracy: 0.6317708333333333
At round 46 training loss: 0.8801782528373102
gradient difference: 61.370892432680314
At round 47 accuracy: 0.559040590405904
At round 47 training accuracy: 0.5969791666666666
At round 47 training loss: 0.924461197014898
gradient difference: 65.26899333507086
At round 48 accuracy: 0.5701107011070111
At round 48 training accuracy: 0.5759375
At round 48 training loss: 0.958795958403498
gradient difference: 69.79724248856382
At round 49 accuracy: 0.6023985239852399
At round 49 training accuracy: 0.596875
At round 49 training loss: 0.9245887935099503
gradient difference: 66.67237342542845
At round 50 accuracy: 0.5267527675276753
At round 50 training accuracy: 0.5247916666666667
At round 50 training loss: 1.0915694206766784
gradient difference: 80.83064755264964
At round 51 accuracy: 0.5498154981549815
At round 51 training accuracy: 0.5509375
At round 51 training loss: 0.9951117578459283
gradient difference: 73.54942081969624
At round 52 accuracy: 0.5525830258302583
At round 52 training accuracy: 0.5816666666666667
At round 52 training loss: 0.9457440164250632
gradient difference: 68.22640782601607
At round 53 accuracy: 0.6522140221402214
At round 53 training accuracy: 0.6652083333333333
At round 53 training loss: 0.8350255481960873
gradient difference: 58.241551600619026
At round 54 accuracy: 0.6411439114391144
At round 54 training accuracy: 0.6778125
At round 54 training loss: 0.8175382493653646
gradient difference: 56.42249196861453
At round 55 accuracy: 0.6180811808118081
At round 55 training accuracy: 0.6511458333333333
At round 55 training loss: 0.8325121286511421
gradient difference: 57.29291742648582
At round 56 accuracy: 0.6171586715867159
At round 56 training accuracy: 0.6542708333333334
At round 56 training loss: 0.8212368281868597
gradient difference: 55.73324293178919
At round 57 accuracy: 0.5701107011070111
At round 57 training accuracy: 0.6109375
At round 57 training loss: 0.8655689854081721
gradient difference: 59.48206250710635
At round 58 accuracy: 0.5581180811808119
At round 58 training accuracy: 0.5892708333333333
At round 58 training loss: 0.9094022944228103
gradient difference: 62.66180326497627
At round 59 accuracy: 0.5166051660516605
At round 59 training accuracy: 0.5429166666666667
At round 59 training loss: 1.1559171086425584
gradient difference: 78.1381323740816
At round 60 accuracy: 0.5645756457564576
At round 60 training accuracy: 0.5859375
At round 60 training loss: 0.9209593562223017
gradient difference: 62.93872005600902
At round 61 accuracy: 0.5682656826568265
At round 61 training accuracy: 0.5941666666666666
At round 61 training loss: 0.8865851119098564
gradient difference: 60.183409552220255
At round 62 accuracy: 0.5811808118081181
At round 62 training accuracy: 0.605
At round 62 training loss: 0.8549823990898827
gradient difference: 56.45224325912935
At round 63 accuracy: 0.6217712177121771
At round 63 training accuracy: 0.6509375
At round 63 training loss: 0.781090221380194
gradient difference: 49.18389117442451
At round 64 accuracy: 0.672509225092251
At round 64 training accuracy: 0.6773958333333333
At round 64 training loss: 0.7606409329300126
gradient difference: 48.13202697926024
At round 65 accuracy: 0.6549815498154982
At round 65 training accuracy: 0.6522916666666667
At round 65 training loss: 0.7867489844933152
gradient difference: 51.39498359468597
At round 66 accuracy: 0.6688191881918819
At round 66 training accuracy: 0.6938541666666667
At round 66 training loss: 0.7378681189535806
gradient difference: 46.57612705795376
At round 67 accuracy: 0.6761992619926199
At round 67 training accuracy: 0.7014583333333333
At round 67 training loss: 0.7263161730797341
gradient difference: 45.561172712647426
At round 68 accuracy: 0.6826568265682657
At round 68 training accuracy: 0.6857291666666666
At round 68 training loss: 0.7380124632300188
gradient difference: 46.05454090882328
At round 69 accuracy: 0.6642066420664207
At round 69 training accuracy: 0.6546875
At round 69 training loss: 0.7648406514277061
gradient difference: 48.0252093063147
At round 70 accuracy: 0.6715867158671587
At round 70 training accuracy: 0.6766666666666666
At round 70 training loss: 0.7370415215970327
gradient difference: 46.15672145713925
At round 71 accuracy: 0.5867158671586716
At round 71 training accuracy: 0.6296875
At round 71 training loss: 0.7905101656137655
gradient difference: 51.91399744982846
At round 72 accuracy: 0.6411439114391144
At round 72 training accuracy: 0.6748958333333334
At round 72 training loss: 0.7342180605605244
gradient difference: 46.84159075864229
At round 73 accuracy: 0.6263837638376384
At round 73 training accuracy: 0.6620833333333334
At round 73 training loss: 0.7460141909091423
gradient difference: 48.079308666939596
At round 74 accuracy: 0.6595940959409594
At round 74 training accuracy: 0.7028125
At round 74 training loss: 0.7071640133081625
gradient difference: 43.78920988275044
At round 75 accuracy: 0.6734317343173432
At round 75 training accuracy: 0.7088541666666667
At round 75 training loss: 0.6935358065770318
gradient difference: 40.79988780899698
At round 76 accuracy: 0.683579335793358
At round 76 training accuracy: 0.668125
At round 76 training loss: 0.736717685541759
gradient difference: 46.29313159657129
At round 77 accuracy: 0.6937269372693727
At round 77 training accuracy: 0.6911458333333333
At round 77 training loss: 0.7108737934598078
gradient difference: 43.0448305161744
At round 78 accuracy: 0.6789667896678967
At round 78 training accuracy: 0.6701041666666666
At round 78 training loss: 0.7322583770720908
gradient difference: 45.77003945089055
At round 79 accuracy: 0.6780442804428044
At round 79 training accuracy: 0.6704166666666667
At round 79 training loss: 0.7339430992056926
gradient difference: 46.1098721329978
At round 80 accuracy: 0.665129151291513
At round 80 training accuracy: 0.65375
At round 80 training loss: 0.7503182309214026
gradient difference: 47.78281706985868
At round 81 accuracy: 0.6881918819188192
At round 81 training accuracy: 0.71375
At round 81 training loss: 0.6851059512111047
gradient difference: 39.96208356643544
At round 82 accuracy: 0.5821033210332104
At round 82 training accuracy: 0.5765625
At round 82 training loss: 0.9151026109792292
gradient difference: 61.40024616702413
At round 83 accuracy: 0.6586715867158671
At round 83 training accuracy: 0.6919791666666667
At round 83 training loss: 0.7002332236338407
gradient difference: 42.184161372904
At round 84 accuracy: 0.6236162361623616
At round 84 training accuracy: 0.6196875
At round 84 training loss: 0.8132342383855333
gradient difference: 53.44141083096897
At round 85 accuracy: 0.5987084870848709
At round 85 training accuracy: 0.6308333333333334
At round 85 training loss: 0.7944862612088521
gradient difference: 51.450465280708855
At round 86 accuracy: 0.6254612546125461
At round 86 training accuracy: 0.658125
At round 86 training loss: 0.7430052609648555
gradient difference: 44.962811850199685
At round 87 accuracy: 0.6457564575645757
At round 87 training accuracy: 0.6801041666666666
At round 87 training loss: 0.7139497215549151
gradient difference: 41.50905345517222
At round 88 accuracy: 0.6226937269372693
At round 88 training accuracy: 0.6548958333333333
At round 88 training loss: 0.7450952166256806
gradient difference: 44.850231183382995
At round 89 accuracy: 0.6291512915129152
At round 89 training accuracy: 0.6611458333333333
At round 89 training loss: 0.7317577206281324
gradient difference: 43.20128657826317
At round 90 accuracy: 0.6512915129151291
At round 90 training accuracy: 0.67875
At round 90 training loss: 0.7059509051125497
gradient difference: 40.815777062262555
At round 91 accuracy: 0.6540590405904059
At round 91 training accuracy: 0.6914583333333333
At round 91 training loss: 0.689847765667364
gradient difference: 38.436902424827295
At round 92 accuracy: 0.6974169741697417
At round 92 training accuracy: 0.7133333333333334
At round 92 training loss: 0.6745497009189179
gradient difference: 37.58777787707507
At round 93 accuracy: 0.6955719557195572
At round 93 training accuracy: 0.7016666666666667
At round 93 training loss: 0.6834431278984994
gradient difference: 39.548950598169625
At round 94 accuracy: 0.7047970479704797
At round 94 training accuracy: 0.7378125
At round 94 training loss: 0.6498179156798869
gradient difference: 33.2585891362836
At round 95 accuracy: 0.7066420664206642
At round 95 training accuracy: 0.736875
At round 95 training loss: 0.6483827657951042
gradient difference: 33.17292400743743
At round 96 accuracy: 0.7011070110701108
At round 96 training accuracy: 0.7370833333333333
At round 96 training loss: 0.64634062048203
gradient difference: 32.86664249573027
At round 97 accuracy: 0.6928044280442804
At round 97 training accuracy: 0.7278125
At round 97 training loss: 0.6448715269876023
gradient difference: 34.47869667907833
At round 98 accuracy: 0.6974169741697417
At round 98 training accuracy: 0.7314583333333333
At round 98 training loss: 0.640908617915896
gradient difference: 34.52022306189279
At round 99 accuracy: 0.6531365313653137
At round 99 training accuracy: 0.6407291666666667
At round 99 training loss: 0.7487702044735973
gradient difference: 46.03008777833872
At round 100 accuracy: 0.698339483394834
At round 100 training accuracy: 0.7036458333333333
At round 100 training loss: 0.6691279595345259
gradient difference: 38.400240667877895
At round 101 accuracy: 0.6937269372693727
At round 101 training accuracy: 0.6834375
At round 101 training loss: 0.6896168045296023
gradient difference: 40.69557873401292
At round 102 accuracy: 0.6872693726937269
At round 102 training accuracy: 0.6773958333333333
At round 102 training loss: 0.6982501107050727
gradient difference: 40.536722789887335
At round 103 accuracy: 0.6992619926199262
At round 103 training accuracy: 0.7007291666666666
At round 103 training loss: 0.6714670681580901
gradient difference: 38.12948470336698
At round 104 accuracy: 0.6346863468634686
At round 104 training accuracy: 0.6285416666666667
At round 104 training loss: 0.7775330313667655
gradient difference: 48.46816891787843
At round 105 accuracy: 0.5959409594095941
At round 105 training accuracy: 0.5945833333333334
At round 105 training loss: 0.8689770068461076
gradient difference: 55.93653935978713
At round 106 accuracy: 0.5940959409594095
At round 106 training accuracy: 0.5947916666666667
At round 106 training loss: 0.8646738469492024
gradient difference: 55.9110308829917
At round 107 accuracy: 0.672509225092251
At round 107 training accuracy: 0.6610416666666666
At round 107 training loss: 0.7194292723418524
gradient difference: 44.111634612451944
At round 108 accuracy: 0.6937269372693727
At round 108 training accuracy: 0.6890625
At round 108 training loss: 0.6821181489946321
gradient difference: 40.73247530386799
At round 109 accuracy: 0.584870848708487
At round 109 training accuracy: 0.6214583333333333
At round 109 training loss: 0.8093353859040265
gradient difference: 51.82050275837097
At round 110 accuracy: 0.5839483394833949
At round 110 training accuracy: 0.6228125
At round 110 training loss: 0.7985175782783578
gradient difference: 51.40615169961837
At round 111 accuracy: 0.5996309963099631
At round 111 training accuracy: 0.636875
At round 111 training loss: 0.7710444348212332
gradient difference: 48.49662821602041
At round 112 accuracy: 0.690959409594096
At round 112 training accuracy: 0.73625
At round 112 training loss: 0.6290125825690727
gradient difference: 35.37008572124307
At round 113 accuracy: 0.6937269372693727
At round 113 training accuracy: 0.7367708333333334
At round 113 training loss: 0.6286360070699205
gradient difference: 35.22066131182691
At round 114 accuracy: 0.6826568265682657
At round 114 training accuracy: 0.721875
At round 114 training loss: 0.6421691075029472
gradient difference: 36.15215269982992
At round 115 accuracy: 0.7112546125461254
At round 115 training accuracy: 0.7086458333333333
At round 115 training loss: 0.6608047936468696
gradient difference: 38.18250380137111
At round 116 accuracy: 0.7084870848708487
At round 116 training accuracy: 0.7089583333333334
At round 116 training loss: 0.6598744290446241
gradient difference: 38.06746603170343
At round 117 accuracy: 0.7001845018450185
At round 117 training accuracy: 0.741875
At round 117 training loss: 0.625779061303474
gradient difference: 34.65283025724727
At round 118 accuracy: 0.7001845018450185
At round 118 training accuracy: 0.74125
At round 118 training loss: 0.6234648966354629
gradient difference: 35.33950359056049
At round 119 accuracy: 0.6937269372693727
At round 119 training accuracy: 0.7398958333333333
At round 119 training loss: 0.6245984982016186
gradient difference: 35.85258646968172
At round 120 accuracy: 0.6928044280442804
At round 120 training accuracy: 0.7416666666666667
At round 120 training loss: 0.6227755258775627
gradient difference: 35.93468481988681
At round 121 accuracy: 0.6946494464944649
At round 121 training accuracy: 0.7395833333333334
At round 121 training loss: 0.6241007053091501
gradient difference: 35.92820021669637
At round 122 accuracy: 0.7001845018450185
At round 122 training accuracy: 0.734375
At round 122 training loss: 0.6319940838745485
gradient difference: 37.284922600568
At round 123 accuracy: 0.6918819188191881
At round 123 training accuracy: 0.7395833333333334
At round 123 training loss: 0.6223153900215402
gradient difference: 36.136067879563484
At round 124 accuracy: 0.6918819188191881
At round 124 training accuracy: 0.739375
At round 124 training loss: 0.6223723283704992
gradient difference: 36.106236065161504
At round 125 accuracy: 0.6900369003690037
At round 125 training accuracy: 0.7396875
At round 125 training loss: 0.6242505667094762
gradient difference: 36.490312930267855
At round 126 accuracy: 0.6872693726937269
At round 126 training accuracy: 0.7332291666666667
At round 126 training loss: 0.6284146658657118
gradient difference: 36.932743427737634
At round 127 accuracy: 0.6854243542435424
At round 127 training accuracy: 0.7375
At round 127 training loss: 0.6251870518379534
gradient difference: 36.48183470861359
At round 128 accuracy: 0.6863468634686347
At round 128 training accuracy: 0.7325
At round 128 training loss: 0.6291392511222511
gradient difference: 36.72951135053625
At round 129 accuracy: 0.6466789667896679
At round 129 training accuracy: 0.6940625
At round 129 training loss: 0.6659707595819296
gradient difference: 41.08846527372233
At round 130 accuracy: 0.6706642066420664
At round 130 training accuracy: 0.718125
At round 130 training loss: 0.6380758033281503
gradient difference: 38.3914144514774
At round 131 accuracy: 0.672509225092251
At round 131 training accuracy: 0.7159375
At round 131 training loss: 0.6400020191119984
gradient difference: 38.44432024868014
At round 132 accuracy: 0.6402214022140221
At round 132 training accuracy: 0.6773958333333333
At round 132 training loss: 0.6821341457272259
gradient difference: 42.795586945955556
At round 133 accuracy: 0.6485239852398524
At round 133 training accuracy: 0.6967708333333333
At round 133 training loss: 0.658753944390143
gradient difference: 40.467293278372516
At round 134 accuracy: 0.6577490774907749
At round 134 training accuracy: 0.6991666666666667
At round 134 training loss: 0.6551024176987509
gradient difference: 39.76185798069953
At round 135 accuracy: 0.6559040590405905
At round 135 training accuracy: 0.7007291666666666
At round 135 training loss: 0.653625975176692
gradient difference: 39.821448090817924
At round 136 accuracy: 0.5977859778597786
At round 136 training accuracy: 0.5982291666666667
At round 136 training loss: 0.8569134515337646
gradient difference: 57.575544858350746
At round 137 accuracy: 0.6319188191881919
At round 137 training accuracy: 0.6329166666666667
At round 137 training loss: 0.7572400527486267
gradient difference: 49.097842299708084
At round 138 accuracy: 0.6595940959409594
At round 138 training accuracy: 0.6509375
At round 138 training loss: 0.7241923041711561
gradient difference: 46.38959229725812
At round 139 accuracy: 0.7020295202952029
At round 139 training accuracy: 0.7403125
At round 139 training loss: 0.6130709049431607
gradient difference: 35.25902714199536
At round 140 accuracy: 0.7001845018450185
At round 140 training accuracy: 0.7451041666666667
At round 140 training loss: 0.6041918231733143
gradient difference: 33.20163069033416
At round 141 accuracy: 0.7121771217712177
At round 141 training accuracy: 0.7486458333333333
At round 141 training loss: 0.5969531721854583
gradient difference: 30.900357883219392
At round 142 accuracy: 0.7121771217712177
At round 142 training accuracy: 0.7480208333333334
At round 142 training loss: 0.5968256229658921
gradient difference: 30.272832123151904
At round 143 accuracy: 0.7130996309963099
At round 143 training accuracy: 0.749375
At round 143 training loss: 0.593836321507891
gradient difference: 29.436841136790243
At round 144 accuracy: 0.7149446494464945
At round 144 training accuracy: 0.7469791666666666
At round 144 training loss: 0.5938795274604732
gradient difference: 29.849842643896523
At round 145 accuracy: 0.6660516605166051
At round 145 training accuracy: 0.6996875
At round 145 training loss: 0.6416540646584084
gradient difference: 35.237776127107416
At round 146 accuracy: 0.6540590405904059
At round 146 training accuracy: 0.6825
At round 146 training loss: 0.6647941853408702
gradient difference: 37.19320153622813
At round 147 accuracy: 0.6614391143911439
At round 147 training accuracy: 0.6917708333333333
At round 147 training loss: 0.6524425905803218
gradient difference: 35.7969010585371
At round 148 accuracy: 0.6457564575645757
At round 148 training accuracy: 0.674375
At round 148 training loss: 0.6773696380597539
gradient difference: 38.20766561112188
At round 149 accuracy: 0.716789667896679
At round 149 training accuracy: 0.7530208333333334
At round 149 training loss: 0.5898093975118051
gradient difference: 29.504737263999207
At round 150 accuracy: 0.7140221402214022
At round 150 training accuracy: 0.7527083333333333
At round 150 training loss: 0.5875127185322344
gradient difference: 28.786905981630994
At round 151 accuracy: 0.7232472324723247
At round 151 training accuracy: 0.7430208333333334
At round 151 training loss: 0.5995799833877633
gradient difference: 30.21490681342412
At round 152 accuracy: 0.7084870848708487
At round 152 training accuracy: 0.7530208333333334
At round 152 training loss: 0.5884344753801513
gradient difference: 29.276747167433193
At round 153 accuracy: 0.7112546125461254
At round 153 training accuracy: 0.7527083333333333
At round 153 training loss: 0.5863553248578682
gradient difference: 29.303211656086276
At round 154 accuracy: 0.7158671586715867
At round 154 training accuracy: 0.7509375
At round 154 training loss: 0.5873397465321856
gradient difference: 29.68481824567575
At round 155 accuracy: 0.7158671586715867
At round 155 training accuracy: 0.7538541666666667
At round 155 training loss: 0.5863385852775537
gradient difference: 29.5057317672615
At round 156 accuracy: 0.7140221402214022
At round 156 training accuracy: 0.7526041666666666
At round 156 training loss: 0.5865892821814244
gradient difference: 29.686779123006733
At round 157 accuracy: 0.705719557195572
At round 157 training accuracy: 0.7419791666666666
At round 157 training loss: 0.5949450434728836
gradient difference: 30.0347673989976
At round 158 accuracy: 0.7001845018450185
At round 158 training accuracy: 0.7322916666666667
At round 158 training loss: 0.6018274147847357
gradient difference: 30.96751925672619
At round 159 accuracy: 0.5922509225092251
At round 159 training accuracy: 0.5875
At round 159 training loss: 0.951007457410451
gradient difference: 58.03696834760313
At round 160 accuracy: 0.6171586715867159
At round 160 training accuracy: 0.6069791666666666
At round 160 training loss: 0.8571996123638624
gradient difference: 52.488889136060415
At round 161 accuracy: 0.6088560885608856
At round 161 training accuracy: 0.5983333333333334
At round 161 training loss: 0.8951675910130144
gradient difference: 54.26655065264697
At round 162 accuracy: 0.6143911439114391
At round 162 training accuracy: 0.60625
At round 162 training loss: 0.8656031652268332
gradient difference: 51.38555124235297
At round 163 accuracy: 0.6549815498154982
At round 163 training accuracy: 0.685625
At round 163 training loss: 0.6617281890877833
gradient difference: 35.62167510396014
At round 164 accuracy: 0.6789667896678967
At round 164 training accuracy: 0.7101041666666666
At round 164 training loss: 0.6253744195215404
gradient difference: 30.971032790965545
At round 165 accuracy: 0.7204797047970479
At round 165 training accuracy: 0.755
At round 165 training loss: 0.5776867783752581
gradient difference: 26.202326335202752
At round 166 accuracy: 0.7158671586715867
At round 166 training accuracy: 0.7477083333333333
At round 166 training loss: 0.5845509848122795
gradient difference: 27.43573635468165
At round 167 accuracy: 0.705719557195572
At round 167 training accuracy: 0.7390625
At round 167 training loss: 0.5918005692920026
gradient difference: 28.09311818821427
At round 168 accuracy: 0.7260147601476015
At round 168 training accuracy: 0.743125
At round 168 training loss: 0.5927823784862024
gradient difference: 28.044649550040365
At round 169 accuracy: 0.716789667896679
At round 169 training accuracy: 0.7494791666666667
At round 169 training loss: 0.5831552451988682
gradient difference: 26.65785744414737
At round 170 accuracy: 0.7195571955719557
At round 170 training accuracy: 0.7405208333333333
At round 170 training loss: 0.5937730753724463
gradient difference: 28.095365636990444
At round 171 accuracy: 0.7177121771217713
At round 171 training accuracy: 0.7548958333333333
At round 171 training loss: 0.5748828909064954
gradient difference: 25.99139817155571
At round 172 accuracy: 0.7158671586715867
At round 172 training accuracy: 0.755
At round 172 training loss: 0.5754578320441457
gradient difference: 26.528923388363115
At round 173 accuracy: 0.709409594095941
At round 173 training accuracy: 0.7547916666666666
At round 173 training loss: 0.5767123995822233
gradient difference: 27.25354274154456
At round 174 accuracy: 0.7121771217712177
At round 174 training accuracy: 0.7529166666666667
At round 174 training loss: 0.576624848752593
gradient difference: 27.49898348557436
At round 175 accuracy: 0.7149446494464945
At round 175 training accuracy: 0.7545833333333334
At round 175 training loss: 0.574376089045157
gradient difference: 27.09834894187468
At round 176 accuracy: 0.6946494464944649
At round 176 training accuracy: 0.676875
At round 176 training loss: 0.6706454752416661
gradient difference: 36.85211643716276
At round 177 accuracy: 0.7158671586715867
At round 177 training accuracy: 0.7159375
At round 177 training loss: 0.6162941113199728
gradient difference: 30.67445322670774
At round 178 accuracy: 0.7214022140221402
At round 178 training accuracy: 0.7211458333333334
At round 178 training loss: 0.6101686579780653
gradient difference: 29.574022900674468
At round 179 accuracy: 0.716789667896679
At round 179 training accuracy: 0.7565625
At round 179 training loss: 0.5741423119022511
gradient difference: 25.78171455468498
At round 180 accuracy: 0.7103321033210332
At round 180 training accuracy: 0.7575
At round 180 training loss: 0.5679047269024886
gradient difference: 24.657801748163244
At round 181 accuracy: 0.7195571955719557
At round 181 training accuracy: 0.7620833333333333
At round 181 training loss: 0.5642077999010993
gradient difference: 23.81168327190115
At round 182 accuracy: 0.7186346863468634
At round 182 training accuracy: 0.7595833333333334
At round 182 training loss: 0.5670940797869116
gradient difference: 24.721389021931465
At round 183 accuracy: 0.724169741697417
At round 183 training accuracy: 0.76125
At round 183 training loss: 0.5645654437093375
gradient difference: 24.55294359582767
At round 184 accuracy: 0.7195571955719557
At round 184 training accuracy: 0.7610416666666666
At round 184 training loss: 0.5691046485731689
gradient difference: 25.538531325092993
At round 185 accuracy: 0.7204797047970479
At round 185 training accuracy: 0.7607291666666667
At round 185 training loss: 0.5658756071212702
gradient difference: 24.20738943451012
At round 186 accuracy: 0.7186346863468634
At round 186 training accuracy: 0.76
At round 186 training loss: 0.5657980373090443
gradient difference: 24.404278510657175
At round 187 accuracy: 0.6383763837638377
At round 187 training accuracy: 0.6705208333333333
At round 187 training loss: 0.6830190856219269
gradient difference: 36.09124929657903
At round 188 accuracy: 0.6485239852398524
At round 188 training accuracy: 0.6766666666666666
At round 188 training loss: 0.6704306081139172
gradient difference: 34.98102596131673
At round 189 accuracy: 0.7214022140221402
At round 189 training accuracy: 0.7610416666666666
At round 189 training loss: 0.5635185366907778
gradient difference: 24.67880580773825
At round 190 accuracy: 0.7223247232472325
At round 190 training accuracy: 0.7634375
At round 190 training loss: 0.5600024757596354
gradient difference: 23.80022760324977
At round 191 accuracy: 0.6881918819188192
At round 191 training accuracy: 0.7264583333333333
At round 191 training loss: 0.59518248211282
gradient difference: 27.692120963333235
At round 192 accuracy: 0.690959409594096
At round 192 training accuracy: 0.7286458333333333
At round 192 training loss: 0.5902391716465354
gradient difference: 27.42859470090798
At round 193 accuracy: 0.7232472324723247
At round 193 training accuracy: 0.7598958333333333
At round 193 training loss: 0.5622158892126754
gradient difference: 24.5816225968506
At round 194 accuracy: 0.7232472324723247
At round 194 training accuracy: 0.7580208333333334
At round 194 training loss: 0.5597131178155541
gradient difference: 24.59305900086521
At round 195 accuracy: 0.6180811808118081
At round 195 training accuracy: 0.6423958333333334
At round 195 training loss: 0.7600635091898342
gradient difference: 42.47780930008326
At round 196 accuracy: 0.6070110701107011
At round 196 training accuracy: 0.6394791666666667
At round 196 training loss: 0.771429398242229
gradient difference: 42.72837471567471
At round 197 accuracy: 0.6116236162361623
At round 197 training accuracy: 0.6407291666666667
At round 197 training loss: 0.7645713339823609
gradient difference: 42.94614490609179
At round 198 accuracy: 0.6014760147601476
At round 198 training accuracy: 0.634375
At round 198 training loss: 0.787846818031588
gradient difference: 44.0136704794648
At round 199 accuracy: 0.7204797047970479
At round 199 training accuracy: 0.7573958333333334
At round 199 training loss: 0.567407162329182
gradient difference: 25.03614338624421
At round 200 accuracy: 0.7223247232472325
At round 200 training accuracy: 0.7236458333333333
