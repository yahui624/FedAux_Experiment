Arguments:
	       batch_size : 10
	clients_per_round : 10
	          dataset : mnist
	     drop_percent : 0.5
	       eval_every : 1
	    learning_rate : 0.01
	            model : mclr
	     model_params : (10,)
	               mu : 0.0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedprox
	             seed : 0
Using Federated prox to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/70.60k flops)
  dense/kernel/Regularizer/l2_regularizer (1/23.52k flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (23.52k/23.52k flops)
  dense/kernel/Initializer/random_uniform (7.84k/15.68k flops)
    dense/kernel/Initializer/random_uniform/mul (7.84k/7.84k flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  PGD/update_dense/kernel/AssignSub (7.84k/7.84k flops)
  PGD/update_dense/kernel/mul (7.84k/7.84k flops)
  PGD/update_dense/kernel/mul_1 (7.84k/7.84k flops)
  PGD/update_dense/kernel/sub (7.84k/7.84k flops)
  PGD/update_dense/bias/AssignSub (10/10 flops)
  PGD/update_dense/bias/mul (10/10 flops)
  PGD/update_dense/bias/mul_1 (10/10 flops)
  PGD/update_dense/bias/sub (10/10 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
0 Clients in Total
Training with 10 workers ---
At round 0 accuracy: nan
At round 0 training accuracy: nan
At round 0 training loss: nan
